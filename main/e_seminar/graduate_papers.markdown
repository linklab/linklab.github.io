---
layout: page
permalink: /seminar/graduate
---

<section class="content-wrapper">
    <article>
    <button class="accordion">2025</button>
        <div class="panel article-content-1">
            <ul>
                <li>12월 9일 (화) 논문 세미나 – 석영준
                    <br/>
                    <strong>
                        Li, Jan, et al. “Optimising entanglement distribution policies under classical communication constraints assisted by reinforcement learning.” Machine Learning: Science and Technology, 2025.
                    </strong>
                    <a href="https://arxiv.org/abs/2412.06938">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                    <br/>
                    <strong>
                        Lai, Hang, et al. "World model-based perception for visual legged locomotion." 2025 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2025.
                    </strong>
                    <a href="https://wmp-loco.github.io/">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>12월 2일 (화) 논문 세미나 – 김진성
                    <br/>
                    <strong>
                        Hafner, Danijar, et al. "Learning latent dynamics for planning from pixels." International conference on machine learning. PMLR, 2019.
                    </strong>
                    <a href="https://arxiv.org/pdf/1811.04551">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                    <br/>
                    <strong>
                        Lai, Hang, et al. "World model-based perception for visual legged locomotion." 2025 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2025.
                    </strong>
                    <a href="https://wmp-loco.github.io/">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>11월 25일 (화) 논문 세미나 – 최요한
                    <br/>
                    <strong>
                       Hafner, Danijar, et al. "Mastering diverse control tasks through world models." Nature, 2025.
                    </strong>
                    <a href="https://doi.org/10.1038/s41586-025-08744-2">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                    <a href="https://danijar.com/project/dreamerv3/">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>10월 28일 (화) 논문 세미나 – 김진성
                    <br/>
                    <strong>
                       Wagenmaker, Andrew, et al. "Steering Your Diffusion Policy with Latent Space Reinforcement Learning." Conference on Robot Learning (2025).
                    </strong>
                    <a href="https://diffusion-steering.github.io/">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>10월 15일 (수) 논문 세미나 – 김민준
                    <br/>
                    <strong>
                       Danijar Hafner, Wilson Yan, Timothy Lillicrap. "Training Agents Inside of Scalable World Models" arXiv preprint arXiv:2509.24527 (2025).
                    </strong>
                    <a href="https://arxiv.org/abs/2509.24527">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>9월 3일 (수) 논문 세미나 – 최요한
                    <br/>
                    <strong>
                        Ho, Jonathan, Ajay Jain, and Pieter Abbeel. "Denoising diffusion probabilistic models." NeurIPS, 2020.
                    </strong>
                    <a href="https://arxiv.org/abs/2006.11239">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>8월 22일 (금) 논문 세미나 – 강대건
                    <br/>
                    <strong>
                        Kenneth Goodenough, Tim Coopmans, Don Towsley, et al. "On noise in swap ASAP repeater chains: exact analytics, distributions and tight approximations" Quantum Physics, 2025.
                    </strong>
                    <a href="https://arxiv.org/abs/2404.07146v5">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>8월 13일 (수) 논문 세미나 – 김진성
                    <br/>
                    <strong>
                        Zhao, Tony Z., et al. "Learning fine-grained bimanual manipulation with low-cost hardware." Robotics: Science and Systems, 2023.
                    </strong>
                    <a href="https://tonyzhaozh.github.io/aloha/">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                    <br/>
                    <strong>
                        Fu, Zipeng, Tony Z. Zhao, and Chelsea Finn. "Mobile aloha: Learning bimanual mobile manipulation with low-cost whole-body teleoperation." Conference on Robot Learning, 2024.
                    </strong>
                    <a href="https://mobile-aloha.github.io/">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>7월 30일 (수) 논문 세미나 – 김민준
                    <br/>
                    <strong>
                        Bjorck, Johan, et al. "Gr00t n1: An open foundation model for generalist humanoid robots." arXiv preprint arXiv:2503.14734 (2025).
                    </strong>
                    <a href="https://arxiv.org/abs/2503.14734">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>7월 10일 (목) 논문 세미나 – 석영준
                    <br/>
                    <strong>
                        Haldar, Stav, et al. "Fast and reliable entanglement distribution with quantum repeaters: Principles for improving protocols using reinforcement learning." Physical Review Applied 21.2 (2024).
                    </strong>
                    <a href="https://arxiv.org/abs/2303.00777">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>7월 03일 (목) 논문 세미나 – 최요한
                    <br/>
                    <strong>
                        Kim, Hyeongjun, et al. "High-speed control and navigation for quadrupedal robots on complex and discrete terrain." Science Robotics, 2025.
                    </strong>
                    <a href="https://www.science.org/doi/10.1126/scirobotics.ads6192">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>6월 11일 (수) 논문 세미나 – 아셀
                    <br/>
                    <strong>
                        Peng Xu, Xiatian Zhu, and David A. Clifton, et al. "Multimodal Learning With Transformers: A Survey." IEEE Transactions on Pattern Analysis and Machine Intelligence, 2023.
                    </strong>
                    <a href="https://ieeexplore.ieee.org/abstract/document/10123038">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>6월 05일 (목) 논문 세미나 – 석영준
                    <br/>
                    <strong>
                        Fayyaz, Anoosha, et al. "On Selecting Paths for End-to-End Entanglement Creation in Quantum Networks." arXiv preprint arXiv:2505.02283 (2025).
                    </strong>
                    <a href="https://arxiv.org/abs/2505.02283">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>5월 28일 (수) 논문 세미나 – 김민준
                    <br/>
                    <strong>
                        Black, Kevin, et al. "π0: A vision-language-action flow model for general robot control, arXiv, 2024."
                    </strong>
                    <a href="https://www.physicalintelligence.company/download/pi0.pdf">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>5월 14일 (수) 논문 세미나 – 지창훈
                    <br/>
                    <strong>
                        Garg, Divyansh, et al. "Iq-learn: Inverse soft-q learning for imitation." Advances in Neural Information Processing Systems 34 (2021): 4028-4039.
                    </strong>
                    <a href="https://proceedings.nips.cc/paper/2021/file/210f760a89db30aa72ca258a3483cc7f-Paper.pdf">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>4월 30일 (수) 논문 세미나 – 석영준
                    <br/>
                    <strong>
                        Roik, J., Bartkiewicz, K., Černoch, A. et al. "Routing in quantum communication networks using reinforcement machine learning". Quantum Inf Process 23, 89 (2024).
                    </strong>
                    <a href="https://link.springer.com/article/10.1007/s11128-024-04287-z#citeas">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>4월 23일 (수) 논문 세미나 – 최요한
                    <br/>
                    <strong>
                        Agarwal, Ananye, et al. "Legged locomotion in challenging terrains using egocentric vision." Conference on robot learning (CoRL), 2022.
                    </strong>
                    <a href="https://vision-locomotion.github.io/">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>4월 16일 (수) 논문 세미나 – 아셀
                    <br/>
                    <strong>
                        Qinqing Zheng, Amy Zhang, and Aditya Grover, "Online Decision Transformer." ICML, 2022.
                    </strong>
                    <a href="https://arxiv.org/abs/2202.05607">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>3월 26일 (수) 논문 세미나 – 김민준
                    <br/>
                    <strong>
                        I Made Aswin Nahrendra, et al. "DreamWaQ: Learning Robust Quadrupedal Locomotion With Implicit Terrain Imagination via Deep Reinforcement Learning." ICRA, 2023.
                    </strong>
                    <a href="https://arxiv.org/abs/2301.10602">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>3월 14일 (금) 논문 세미나 – 지창훈
                    <br/>
                    <strong>
                        Yu, Wenhao, et al. "Language to rewards for robotic skill synthesis." Conference on Robot Learning (CoRL), 2023.
                    </strong>
                    <a href="https://proceedings.mlr.press/v229/yu23a.html">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>2월 25일 (화) 논문 세미나 – 석영준
                    <br/>
                    <strong>
                        Tabish Rashid, Mikayel Samvelyan, et al. "QMIX: Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning." Journal of Machine Learning Research, 2020.
                    </strong>
                    <a href="https://www.jmlr.org/papers/v21/20-081.html">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>2월 12일 (수) 논문 세미나 – 최요한
                    <br/>
                    <strong>
                        Hoeller, David, et al. "Anymal parkour: Learning agile navigation for quadrupedal robots." Science Robotics, 2024.
                    </strong>
                    <a href="https://www.science.org/doi/full/10.1126/scirobotics.adi7566">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>2월 4일 (화) 논문 세미나 – 아셀
                    <br/>
                    <strong>
                        I. Adamski, R. Adamski, T. Grel, A. Jędrych, K. Kaczmarek, H. Michalewski, et al. "Distributed Deep Reinforcement Learning: Learn how to play Atari games in 21 minutes." High Performance Computing (ISC High Performance)
                        2018 – 33rd International Conference, 2018.
                    </strong>
                    <a href="https://arxiv.org/abs/1801.02852">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>1월 21일 (화) 논문 세미나 – 김민준
                    <br/>
                    <strong>
                        Gabriel B. Margolis, Pulkit Agrawal. "Walk These Ways: Tuning Robot Control for Generalization with Multiplicity of Behavior." Conference on Robot Learning (CoRL), 2022.
                    </strong>
                    <a href="https://arxiv.org/pdf/2212.03238">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>1월 15일 (수) 논문 세미나 – 지창훈
                    <br/>
                    <strong>
                        Rocha, Lidia, et al. "Enhancing Safety via Deep Reinforcement Learning in Trajectory Planning for Agile Flights in Unknown Environments." IROS, 2024.
                    </strong>
                    <a href="https://ieeexplore.ieee.org/abstract/document/10801910">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
            </ul>
        </div>
        <button class="accordion">2024</button>
        <div class="panel article-content-1">
            <ul>
                <li>12월 30일 (월) 논문 세미나 – 최요한
                    <br/>
                    <strong>
                        Kumar, Ashish, et al. "RMA: Adapting rapid motor adaptation for bipedal robots." 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 2022.
                    </strong>
                    <a href="https://ieeexplore.ieee.org/abstract/document/9981091">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>12월 23일 (월) 논문 세미나 – 아셀
                    <br/>
                    <strong>
                        A. Nair, P. Srinivasan, S. Blackwell, C. Alcicek, R. Fearon, A. De Maria, V. Panneershelvam, M. Suleyman, 
                        C. Beattie, S. Petersen, S. Legg, V. Mnih, K. Kavukcuoglu, D. Silver, et al. "Massively Parallel Methods for Deep Reinforcement Learning." International Conference on Machine Learning, 2015.
                    </strong>
                    <a href="https://arxiv.org/abs/1507.04296">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>12월 13일 (금) 논문 세미나 – 김주봉
                    <br/>
                    <strong>
                        Alin-Bogdan Popa, Pantelimon George Popescu, et al. "The Future of QKD Networks." arXiv:2407.00877v1, 2024.
                    </strong>
                    <a href="https://arxiv.org/abs/2407.00877">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a><br/>
                    <strong>
                        Johann T., Kühl S., & Pachnicke S., et al. "Deep Reinforcement Learning based Decentralized Routing and Load-Balancing in Meshed QKD-Networks." ECOC, 2024.
                    </strong>
                    <a href="https://www.ecoc2024.org/wp-content/uploads/2024/09/240908_ECOC-2024_Programm_8_WEB.pdf">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>12월 3일 (화) 논문 세미나 – 최호빈
                    <br/>
                    <strong>
                        CX. Gao, C. Wu, M. Cao, R. Kong, Z. Zhang, Y. Yu, et al. "ACT: Empowering Decision Transformer with Dynamic Programming via
                        Advantage Conditioning." AAAI, 2024.
                    </strong>
                    <a href="https://arxiv.org/abs/2309.05915">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>11월 26일 (화) 논문 세미나 – 석영준
                    <br/>
                    <strong>
                        Z. Zheng, C. Zhou, X. Tong, M. Yuan, Z. Wang, et al. "UDC: A Unified Neural Divide-and-Conquer Framework for Large-Scale Combinatorial
                        Optimization Problems." NIPS, 2024.
                    </strong>
                    <a href="https://arxiv.org/pdf/2407.00312">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>11월 19일 (화) 논문 세미나 – 최요한
                    <br/>
                    <strong>
                        Zhuang, Ziwen, et al. "Robot parkour learning." CoRL, 2023.
                    </strong>
                    <a href="https://robot-parkour.github.io/">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>11월 12일 (화) 논문 세미나 – 지창훈
                    <br/>
                    <strong>
                        Yu, Wenhao, et al. "Pathrl: An end-to-end path generation method for collision avoidance via deep reinforcement learning," ICRA, 2024.
                    </strong>
                    <a href="https://ieeexplore.ieee.org/abstract/document/10610107">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>11월 05일 (화) 논문 세미나 – 최호빈
                    <br/>
                    <strong>
                        Wang, Yuanfu, et al., "Critic-guided decision transformer for offline reinforcement learning," AAAI, Vol. 38, No. 14, 2024.
                    </strong>
                    <a href="https://ojs.aaai.org/index.php/AAAI/article/view/29499">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>10월 29일 (화) 논문 세미나 – 아셀
                    <br/>
                    <strong>
                        H.-K. Lim, J.-B. Kim, I. Ullah, J.-S. Heo, and Y.-H. Han, "Federated Reinforcement Learning Acceleration Method for Precise Control of Multiple Devices", IEEE, 2021.
                    </strong>
                    <a href="https://ieeexplore.ieee.org/abstract/document/9439484">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>10월 22일 (화) 논문 세미나 – 석영준
                    <br/>
                    <strong>
                        T. Islam, M. Arifuzzaman and E. Arslan, "Reinforcement Learning Based Proactive Entanglement Swapping for Quantum Networks", IEEE, 2024.
                    </strong>
                    <a href="https://ieeexplore.ieee.org/document/10628215">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>10월 15일 (화) 논문 세미나 – 최요한
                    <br/>
                    <strong>
                        Cheng, Xuxin and Shi, Kexin and Agarwal, Ananye and Pathak, Deepak, "Extreme Parkour with Legged Robots", ICRA, 2024.
                    </strong>
                    <a href="https://extreme-parkour.github.io/">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                    <a href="https://ieeexplore.ieee.org/document/10610200">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>10월 8일 (화) 논문 세미나 – 한연희
                    <br/>
                    <strong>
                        Aviral Kumar, Aurick Zhou, George Tucker, Sergey Levine, "Conservative Q-Learning for Offline Reinforcement Learning" NIPS, 2020.
                    </strong>
                    <a href="https://sites.google.com/view/cql-offline-rl">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>10월 1일 (화) 논문 세미나 – 지창훈
                    <br/>
                    <strong>
                        Allevato, Adam, et al. "Tunenet: One-shot residual tuning for system identification and sim-to-real robot task transfer." Conference on Robot Learning. PMLR, 2020.
                    </strong>
                    <a href="https://proceedings.mlr.press/v100/allevato20a.html">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a><br/>
                    <strong>
                        Du, Yuqing, et al. "Auto-tuned sim-to-real transfer." ICRA, 2021.
                    </strong>
                    <a href="https://ieeexplore.ieee.org/abstract/document/9562091">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>09월 23일 (월) 논문 세미나 – 최호빈
                    <br/>
                    <strong>
                        Xie, Zhihui, et al., "Future-conditioned unsupervised pretraining for decision transformer," ICML, 2023.
                    </strong>
                    <a href="https://proceedings.mlr.press/v202/xie23b/xie23b.pdf">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>09월 10일 (화) 논문 세미나 – 최요한
                    <br/>
                    <strong>
                        Luo, Fu, et al. "Neural combinatorial optimization with heavy decoder: Toward large scale generalization." Advances in Neural Information Processing Systems 36 (2023): 8845-8864.
                    </strong>
                    <a href="https://neurips.cc/virtual/2023/poster/71671">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>08월 20일 (화) 논문 세미나 – 최요한
                    <br/>
                    <strong>
                        Sferrazza, Carmelo, et al. "Body Transformer: Leveraging Robot Embodiment for Policy Learning." RSS Workshop, 2024.
                    </strong>
                    <a href="https://sferrazza.cc/bot_site/">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>08월 14일 (수) 논문 세미나 – 지창훈
                    <br/>
                    <strong>
                        Yang, Zhao, et al. "Continuous episodic control." 2023 IEEE Conference on Games (CoG). IEEE, 2023.
                    </strong>
                    <a href="https://arxiv.org/abs/2211.15183">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                    <br/>
                    <strong>
                        Kuznetsov, Igor, and Andrey Filchenkov. "Solving continuous control with episodic memory." IJCAI, 2021.
                    </strong>
                    <a href="https://www.ijcai.org/proceedings/2021/0365.pdf">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>08월 06일 (화) 논문 세미나 – 최호빈
                    <br/>
                    <strong>
                        Ma, Xiao, and Li, Wu-Jun, "Weighting Online Decision Transformer with Episodic Memory for Offline-to-Online Reinforcement Learning," ICRA, 2024.
                    </strong>
                    <a href="https://events.infovaya.com/uploads/documents/pdfviewer/1d/8e/132760-2282.pdf">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>07월 30일 (화) 논문 세미나 – 석영준
                    <br/>
                    <strong>
                        Y. Gao, S. Yang, F. Li and X. Fu, "Adaptive and Efficient Qubit Allocation Using Reinforcement Learning in Quantum Networks," in IEEE Network, vol. 36, no. 5, pp. 48-54, September/October 2022
                    </strong>
                    <a href="https://ieeexplore.ieee.org/abstract/document/9964011" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>07월 15일 (월) 논문 세미나 – 아셀
                    <br/>
                    <strong>
                        Irwan Bello, Hieu Pham, Quoc V. Le, Mohammad Norouzi, Samy Bengio. "Neural Combinatorial Optimization with Reinforcement Learning", ICLR, 2017.
                    </strong>
                    <a href="https://arxiv.org/abs/1611.09940" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>07월 11일 (목) 논문 세미나 – 김주봉
                    <br/>
                    <strong>
                        Yang Zhang, Chenjia Bai, Bin Zhao, Junchi Yan, Xiu Li1, Xuelong Li, "Decentralized Transformers with Centralized Aggregation are Sample-Efficient Multi-Agent World Models," arXiv:2406.15836v1, 2024.
                    </strong>
                    <a href="https://arxiv.org/pdf/2406.15836" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>07월 10일 (수) 논문 세미나 – 아셀
                    <br/>
                    <strong>
                        Oriol Vinyals, Meire Fortunato, Navdeep Jaitly. "Pointer Networks", NIPS, 2015.
                    </strong>
                    <a href="https://arxiv.org/abs/1506.03134" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                    <br/>
                    <strong>
                        Irwan Bello, Hieu Pham, Quoc V. Le, Mohammad Norouzi, Samy Bengio. "Neural Combinatorial Optimization with Reinforcement Learning", ICLR, 2017.
                    </strong>
                    <a href="https://arxiv.org/abs/1611.09940" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>07월 02일 (화) 논문 세미나 – 이재원
                    <br/>
                    <strong>
                        Seungeun Rho, Laura Smith, Tianyu Li, Sergey Levine, Xue Bin Peng, Sehoon Ha. "Language Guided Skill Discovery," arXiv preprint, 2024.
                    </strong>
                    <a href="https://arxiv.org/abs/2406.06615" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>06월 17일 (월) 논문 세미나 – 최요한
                    <br/>
                    <strong>
                        Rudin, N., Hoeller, D., Reist, P., & Hutter, M. Learning to walk in minutes using massively parallel deep reinforcement learning, CoRL, 2022.
                    </strong>
                    <a href="https://proceedings.mlr.press/v164/rudin22a" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>06월 11일 (화) 논문 세미나 – 김주봉
                    <br/>
                    <strong>
                        L. Le, T. N. Nguyen, A. Lee and B. Dumba, "Entanglement Routing For Quantum Networks: A Deep Reinforcement Learning Approach," ICC 2022 - IEEE International Conference on Communications, 2022.
                    </strong>
                    <a href="https://ieeexplore.ieee.org/document/9839240" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>06월 04일 (화) 논문 세미나 – 지창훈
                    <br/>
                    <strong>
                        Liu, Yi, et al. "Efficient preference-based reinforcement learning using learned dynamics models," ICRA, 2023.
                    </strong>
                    <a href="https://arxiv.org/abs/2301.04741" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>05월 30일 (목) 논문 세미나 – 최호빈
                    <br/>
                    <strong>
                        Wu, Yueh-Hua, Xiaolong Wang, and Masashi Hamaya, "Elastic decision transformer," NIPS, 2024.
                    </strong>
                    <a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/3b3889d313ba9476c12c2d77ea66b24f-Paper-Conference.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>05월 21일 (화) 논문 세미나 – 석영준
                    <br/>
                    <strong>
                        Pace, Roy, "Reinforcement Learning in a Quantum Network" (2022). Honors Theses. 1144.
                    </strong>
                    <a href="https://repository.lsu.edu/cgi/viewcontent.cgi?article=2130&context=honors_etd" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>05월 14일 (화) 논문 세미나 – 이재원
                    <br/>
                    <strong>
                        Yecheng Jason Ma, William Liang, Hung-Ju Wang, Sam Wang, Yuke Zhu, Linxi "Jim" Fan, Osbert Bastani, Dinesh Jayaraman. "DrEureka: Language Model Guided Sim-To-Real Transfer," arXiv preprint, 2024.
                    </strong>
                    <a href="https://eureka-research.github.io/dr-eureka/assets/dreureka-paper.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>04월 23일 (화) 논문 세미나 – 지창훈
                    <br/>
                    <strong>
                        Romero, Angel, Yunlong Song, and Davide Scaramuzza. "Actor-critic model predictive control," ICRA ,2024.
                    </strong>
                    <a href="https://arxiv.org/pdf/2306.09852.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>04월 16일 (화) 논문 세미나 – 최호빈
                    <br/>
                    <strong>
                        Zheng, Qinqing, Amy Zhang, and Aditya Grover, "Online decision transformer," ICML, PMLR, 2022.
                    </strong>
                    <a href="https://proceedings.mlr.press/v162/zheng22c/zheng22c.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>04월 09일 (화) 논문 세미나 – 이재원
                    <br/>
                    <strong>
                        Timothy P. Lillicrap, Jonathan J. Hunt, Alexander Pritzel, Nicolas Heess, Tom Erez, Yuval Tassa, David Silver, Daan Wierstra, "Continuous control with deep reinforcement learning," ICLR, 2016.
                    </strong>
                    <a href="https://arxiv.org/pdf/1509.02971" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>04월 02일 (화) 논문 세미나 – 최요한
                    <br/>
                    <strong>
                        Laura Smith, Ilya Kostrikov, Sergey Levine. "Demonstrating a walk in the park: Learning to walk in 20 minutes with model-free reinforcement learning." Robotics: Science and Systems, 2023.
                    </strong>
                    <a href="https://roboticsconference.org/2023/program/papers/056/" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>03월 26일 (화) 논문 세미나 – 김주봉
                    <br/>
                    <strong>
                        Mingyang Wang, Zhenshan Bing, Xiangtong Yao, Shuai Wang, Huang Kai, Hang Su, Chenguang Yang, Alois Knoll. "Meta-Reinforcement Learning Based on Self-Supervised Task Representation Learning," AAAI, 2023.
                    </strong>
                    <a href="https://ojs.aaai.org/index.php/AAAI/article/view/26210" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>03월 19일 (화) 논문 세미나 – 석영준
                    <br/>
                    <strong>
                        Jin, Yan, et al. "Pointerformer: Deep reinforced multi-pointer transformer for the traveling salesman problem." Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 37. No. 7. 2023.
                    </strong>
                    <a href="https://arxiv.org/abs/2304.09407" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>03월 14일 (목) 논문 세미나 – 이재원
                    <br/>
                    <strong>
                        Yuqing Du, Olivia Watkins, et al., "Guiding Pretraining in Reinforcement Learning with Large Language Models," ICML, 2023.
                    </strong>
                    <a href="https://arxiv.org/abs/2302.06692" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>03월 05일 (화) 논문 세미나 – 지창훈
                    <br/>
                    <strong>
                        Ahmadian, Arash, et al. "Back to Basics: Revisiting REINFORCE Style Optimization for Learning from Human Feedback in LLMs." arXiv preprint, 2024.
                    </strong>
                    <a href="https://arxiv.org/abs/2402.14740" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>02월 29일 (목) 논문 세미나 – 최호빈
                    <br/>
                    <strong>
                        Yuan, Minghai, et al., "Research on flexible job shop scheduling problem with AGV using double DQN," Journal of Intelligent Manufacturing, 2023.
                    </strong>
                    <a href="https://link.springer.com/article/10.1007/s10845-023-02252-8" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>02월 20일 (화) 논문 세미나 – 최요한
                    <br/>
                    <strong>
                        Tianwei Ni, Michel Ma, Benjamin Eysenbach, Pierre-Luc Bacon. "When Do Transformers Shine in RL? Decoupling Memory from Credit Assignment." Advances in Neural Information Processing Systems, 2023.
                    </strong>
                    <a href="https://nips.cc/virtual/2023/oral/73869" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                    <a href="https://papers.nips.cc/paper_files/paper/2023/hash/9dc5accb1e4f4a9798eae145f2e4869b-Abstract-Conference.html" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>02월 13일 (화) 논문 세미나 – 김주봉
                    <br/>
                    <strong>
                        Jacob Beck, Matthew Jackson, Risto Vuorio, Shimon Whiteson. "Hypernetworks in Meta-Reinforcement Learning," CoRL, 2022.
                    </strong>
                    <a href="https://openreview.net/pdf?id=N-HtsQkRotI" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>01월 30일 (수) 논문 세미나 – 최요한
                    <br/>
                    <strong>
                        Tianwei Ni, Benjamin Eysenbach, Ruslan Salakhutdinov. "Recurrent Model-Free RL Can Be a Strong Baseline for Many POMDPs." International Conference on Machine Learning, 2022.
                    </strong>
                    <a href="https://sites.google.com/view/pomdp-baselines" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>01월 23일 (화) 논문 세미나 – 이재원, 석영준
                    <br/>
                    <strong>
                        Pouryousef, Shahrooz, et al. "Quantum Network Planning for Utility Maximization." Proceedings of the 1st Workshop on Quantum Networks and Distributed Quantum Computing. 2023.
                    </strong>
                    <a href="https://dl.acm.org/doi/abs/10.1145/3610251.3610553" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                    <br/>
                    <strong>
                        Cicconetti, Claudio, Marco Conti, and Andrea Passarella. "Request scheduling in quantum networks." IEEE Transactions on Quantum Engineering 2 (2021): 2-17.
                    </strong>
                    <a href="https://ieeexplore.ieee.org/abstract/document/9461156" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>01월 16일 (수) 논문 세미나 – 최호빈
                    <br/>
                    <strong>
                        Zhang, Lixiang, Yan Yan, and Yaoguang Hu., "Deep reinforcement learning for dynamic scheduling of energy-efficient automated guided vehicles," Journal of Intelligent Manufacturing, 2023.
                    </strong>
                    <a href="https://link.springer.com/article/10.1007/s10845-023-02208-y" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>01월 10일 (수) 논문 세미나 – 지창훈
                    <br/>
                    <strong>
                        Chebotar, Yevgen, et al. "Q-transformer: Scalable offline reinforcement learning via autoregressive q-functions." Conference on Robot Learning. PMLR, 2023.
                    </strong>
                    <a href="https://proceedings.mlr.press/v229/chebotar23a.html" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>01월 02일 (화) 논문 세미나 – 김주봉
                    <br/>
                    <strong>
                        Carlos Betancourt, Wen-Hui Chen. "Deep reinforcement learning for portfolio management of markets with a dynamic number of assets," Expert Systems With Applications, 2020.
                    </strong>
                    <a href="https://pdf.sciencedirectassets.com/271506/1-s2.0-S0957417420X00182/1-s2.0-S0957417420307776/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEKX%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIQDXNKs3u4lxBZNv8R8WkzTwD2ZkOQeku%2FpvAACf7%2Fy3zgIgVt8vacfWxBTDgrAVQCWybb4MKDhM0Z64QWxSbyb7BWAqsgUIPhAFGgwwNTkwMDM1NDY4NjUiDN3zlE619e20eZEbayqPBU2Ulk%2BB935%2Fg3d3sPjlGXaJ7e3HpABkHuJbNsUH8Cygk6Dl38fxEO8BuPjtz9OOYfj%2BEoohtIauXtsfoP%2F6MeyapS6ZLvY0zpWIM%2FPnaMS9r1arTr0Wjt8a%2BjkdcawM0JFjXobDJS6fzDr%2BOrJ6K20CbmT%2Fw0qXG%2FC6GVzoOmVB7GI%2FWd4jd%2FlzuYrb550N2arseGp0Mf0sg2KyZ8FQ25rkQ10tkv3jcSZkCksIZ%2Fd6ScDkJn340BQFvoMowXcEBcHiv9VTlAhZFx0vr%2Beo23nNBbQZ1mggf%2BjEEAnOq8Ii0GARtiIav1FdEEdb3Df8sCmImWoyDrgQkDAsChgGyH3Sa7G3A3CJ3QVjuPgNfsAeiHNazxnVANz%2B9wrmmpFnLrx9DoKdVBlPdQcK3m%2BrlCIwNGZ0HV%2BlXtGqN5y%2BlUA8xF5RZ9QYaEjjJQnqOrWtTugLZK75pKx7vnB%2FS3G0lftzEzGyGJDq7EPXyPKKis5mgC7yvnGgJq3RLmf1kbdBlRRpnc7H66ZRz81Caqs78m%2FpGFH%2FdHFjZdNO50i2jmFg%2FcGgi42CqR%2BJzdFWYFla4tQMAqADF3So%2BzkOPKZ28D2%2F7vlK1GZXFrXJ7FLPCOREaDX92fjqX%2BOk1Ra7coclxY0kd6sh0tae8pWsTLfKSaNwn7ZUGQwuxvlboD7r%2Fj4ZMIWfeIp9ZBMrFTXA5r8FnPUB9yi3nTF9SysDPMRE318qHka4prindop3UzP3lCzFT2pJhdooyuZn3eTrKmzeupVoL2LhoZyCuKeSYmbj%2BOYph0Q2u2sd2w4pjI%2BSJcc1Pg0eZNRlrl0WmksxEpBG5Yw%2BTtzDonkvpEd5S5KlzqIKivq5QEooEq8yQHxT4Jowxq%2FOrAY6sQHM9ac0qoh%2BaOogKMFWlDZRFXv9jteM6bc3HI3SK9WOTthyajizh5DC5r2E2j19nwDC3TSnr58J6IaNrBM8ALnUcNXjHcvlEWQy7Qw1AZh40cKN84CVyrA%2BYmjC%2BvQBIS41It6rqGeZjaDAS8%2BmWniPXs2GczTlj7h9aGK3mx91swv0p0%2FF%2F3OyGg5XIalqiYDYSCE6CM2R%2BF%2B%2BZRbmNUPlYXV6qgRt%2BQ3XvPoZT%2FxaO%2Fc%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20240102T055651Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTYZTN77ST6%2F20240102%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=29a697198703d5982cc0cefe4963a1fcd5e5c4feffd600ec7f56fb700a550032&hash=776a52695bc41126ecc64bd8a2d70bd4d11f04356e5fc405cb9516fd3f32d989&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S0957417420307776&tid=spdf-24b19fb0-9278-4e0f-a0b2-5fe1554e566e&sid=6b1e3bc57701f7460939bcb33f2a9863dccdgxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=0d1d585c0754005507&rr=83f0c2dd698d9338&cc=kr" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
            </ul>
        </div>
        <button class="accordion">2023</button>
        <div class="panel article-content-1">
            <ul>
                <li>12월 26일 (화) 논문 세미나 – 석영준
                    <br/>
                    <strong>
                        Mai, Xuan, Quanzhi Fu, and Yi Chen. "Packet routing with graph attention multi-agent reinforcement learning." 2021 IEEE Global Communications Conference (GLOBECOM). IEEE, 2021.
                    </strong>
                    <a href="https://arxiv.org/abs/2107.13181" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                    <br/>
                    <strong>
                        Zuo, Yingmin, et al. "Reinforcement learning-based resource allocation in quantum key distribution networks." Asia Communications and Photonics Conference. Optica Publishing Group, 2020.
                    </strong>
                    <a href="https://ieeexplore.ieee.org/document/9365541" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>12월 19일 (화) 논문 세미나 – 이재원
                    <br/>
                    <strong>
                        Tianbao Xie, Siheng Zhao, et al. "Text2Reward: Automated Dense Reward Function Generation for Reinforcement Learning," arXiv, 2023.
                    </strong>
                    <a href="https://arxiv.org/abs/2309.11489" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>12월 12일 (화) 논문 세미나 – 지창훈
                    <br/>
                    <strong>
                        Lee, Kyowoon, Seongun Kim, and Jaesik Choi, "Adaptive and Explainable Deployment of Navigation Skills via Hierarchical Deep Reinforcement Learning," arXiv, 2023.
                    </strong>
                    <a href="https://arxiv.org/abs/2305.19746" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>12월 05일 (화) 논문 세미나 – 최호빈
                    <br/>
                    <strong>
                        Nachum, Ofir, et al., "Why does hierarchy (sometimes) work so well in reinforcement learning?," arXiv preprint arXiv:1909.10618, 2019.
                    </strong>
                    <a href="https://arxiv.org/pdf/1909.10618.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>11월 28일 (화) 논문 세미나 – 김주봉
                    <br/>
                    <strong>
                        Yun-HsuanLien, Yuan-KuiLi, Yu-ShuenWang. "Contrastive Learning and Reward Smoothing for Deep Portfolio Management," IJCAI, 2023.
                    </strong>
                    <a href="https://www.ijcai.org/proceedings/2023/0441.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>11월 21일 (화) 논문 세미나 – 지창훈
                    <br/>
                    <strong>
                        Anonymous authors. "TD-MPC2: Scalable, Robust World Models for Continuous Control," Under review as a conference paper at ICLR 2024.
                    </strong>
                    <a href="https://www.tdmpc2.com/" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>11월 14일 (화) 논문 세미나 – 석영준
                    <br/>
                    <strong>
                        Ayush Jain, Norio Kosaka, Kyung-Min Kim, Joseph J Lim. "Know Your Action Set: Learning Action Relations for Reinforcement Learning," ICLR Conference, 2022.
                    </strong>
                    <a href="https://openreview.net/forum?id=MljXVdp4A3N" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>11월 07일 (화) 논문 세미나 – 이재원
                    <br/>
                    <strong>
                        Yecheng Jason Ma, William Liang, et al. "Eureka: Human-Level Reward Design via Coding Large Language Models," arXiv, 2023.
                    </strong>
                    <a href="https://arxiv.org/abs/2310.12931" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>10월 31일 (화) 논문 세미나 – 최요한
                    <br/>
                    <strong>
                        Xuanhao Pan, Yan Jin, et al. "H-TSP: Hierarchically Solving the Large-Scale Travelling Salesman Problem." AAAI, 2023.
                    </strong>
                    <a href="https://www.microsoft.com/en-us/research/publication/h-tsp-hierarchically-solving-the-large-scale-traveling-salesman-problem/" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>10월 24일 (화) 논문 세미나 – 최호빈
                    <br/>
                    <strong>
                        Cheng-En Wu and Hsiao-Ping Tsai, "Selecting Subgoal for Social AGV Path Planning by Using Reinforcement Learning," 2022 23rd IEEE International Conference on Mobile Data Management (MDM), IEEE, 2022.
                    </strong>
                    <a href="https://ieeexplore.ieee.org/document/9861136" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>10월 10일 (화) 논문 세미나 – 최요한
                    <br/>
                    <strong>
                        Wan, Shanchuan, et al. "DEIR: Efficient and Robust Exploration through Discriminative-Model-Based Episodic Intrinsic Rewards." IJCAI, 2023.
                    </strong>
                    <a href="https://www.ijcai.org/proceedings/2023/477" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>09월 26일 (화) 논문 세미나 – 울라 이산
                    <br/>
                    <strong>
                        Y. Liu, H. Yu, S. Xie and Y. Zhang, "Deep Reinforcement Learning for Offloading and Allocation in Vehicle Edge Computing and Networks" IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY, VOL. 68, NO. 11, NOVEMBER 2019.
                    </strong>
                    <a href="https://ieeexplore.ieee.org/document/8798668" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>09월 13일 (수) 논문 세미나 – 석영준
                    <br/>
                    <strong>
                        Yuan Cao, Yongli Zhao, et al. "Multi-Tenant Provisioning for Quantum Key Distribution Networks With Heuristics and Reinforcement Learning: A Comparative Study," IEEE TRANSACTIONS ON NETWORK AND SERVICE MANAGEMENT, VOL. 17, NO. 2, 2020.
                    </strong>
                    <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8950200" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>08월 30일 (수) 논문 세미나 – 임현교
                    <br/>
                    <strong>
                        Liu, Chenyi, et al. "DRL-OR: Deep Reinforcement Learning-based Online Routing for Multi-type Service Requirements," IEEE INFOCOM 2021 - IEEE Conference on Computer Communications, 2021.
                    </strong>
                    <a href="https://ieeexplore.ieee.org/document/9488736" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>08월 23일 (수) 논문 세미나 – 지창훈
                    <br/>
                    <strong>
                        Qi, Wen, et al. "An adaptive reinforcement learning-based multimodal data fusion framework for human–robot confrontation gaming," Neural Networks, 2023.
                    </strong>
                    <a href="https://www.sciencedirect.com/science/article/pii/S0893608023002290" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>08월 08일 (화) 논문 세미나 – 최호빈
                    <br/>
                    <strong>
                        Ma, Yi, et al., "A hierarchical reinforcement learning based optimization framework for large-scale dynamic pickup and delivery problems," NIPS, 2021.
                    </strong>
                    <a href="https://proceedings.neurips.cc/paper_files/paper/2021/file/c6a01432c8138d46ba39957a8250e027-Paper.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>08월 02일 (수) 논문 세미나 – 최요한
                    <br/>
                    <strong>
                        Yeong-Dae Kwon, Jinho Choo et al., "Matrix encoding networks for neural combinatorial optimization," NIPS, 2021.
                    </strong>
                    <a href="https://proceedings.neurips.cc/paper/2021/file/29539ed932d32f1c56324cded92c07c2-Paper.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>07월 19일 (수) 논문 세미나 – 김주봉
                    <br/>
                    <strong>
                        Luisa Zintgraf, Kyriacos Shiarlis, Maximilian Igl, Sebastian Schulze, Yarin Gal, Katja Hofmann, Shimon Whiteson, "VariBAD: A Very Good Method for Bayes-Adaptive Deep RL via Meta-Learning," ICLR, 2020.
                    </strong>
                    <a href="https://openreview.net/pdf?id=Hkl9JlBYvr" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>07월 11일 (화) 논문 세미나 – 김주봉
                    <br/>
                    <strong>
                        Kate Rakelly*, Aurick Zhou*, Deirdre Quillen, Chelsea Finn, Sergey Levine, "Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables," ICML, 2019.
                    </strong>
                    <a href="http://proceedings.mlr.press/v97/rakelly19a/rakelly19a.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>07월 05일 (수) 논문 세미나 – 최요한
                    <br/>
                    <strong>
                        Daniel J. Mankowitz, Andrea Michi, et al. "Faster sorting algorithms discovered using deep reinforcement learning," Nature, 2023.
                    </strong>
                    <a href="https://www.nature.com/articles/s41586-023-06004-9" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>06월 20일 (화) 논문 세미나 – 지창훈
                    <br/>
                    <strong>
                        Fujimoto, Scott, et al. "For SALE: State-Action Representation Learning for Deep Reinforcement Learning," arXiv, 2023.
                    </strong>
                    <a href="https://arxiv.org/abs/2306.02451" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>06월 13일 (수) 논문 세미나 – 석영준
                    <br/>
                    <strong>
                        Yeong-Dae Kwon, Jinho Choo, et al. "POMO: Policy Optimization with Multiple Optima for Reinforcement Learning," NeurIPS, 2020.
                    </strong>
                    <a href="https://arxiv.org/abs/2010.16011" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>05월 31일 (수) 논문 세미나 – 최호빈
                    <br/>
                    <strong>
                        Hu, Hongtao, et al. "Anti-conflict AGV path planning in automated container terminals based on multi-agent reinforcement learning," International Journal of Production Research, 2023.
                    </strong>
                    <a href="https://www.researchgate.net/profile/Shichang-Xiao/publication/356272643_Anti-conflict_AGV_path_planning_in_automated_container_terminals_based_on_multi-agent_reinforcement_learning/links/62de14fc3c7d190316aa6e22/Anti-conflict-AGV-path-planning-in-automated-container-terminals-based-on-multi-agent-reinforcement-learning.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>05월 23일 (화) 논문 세미나 – 임현교
                    <br/>
                    <strong>
                        Rasool Fakoor, Pratik Chaudhari, et al. "Meta-Q-Learning," ICLR, 2020.
                    </strong>
                    <a href="https://arxiv.org/abs/1910.00125" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>05월 16일 (화) 논문 세미나 – 지창훈
                    <br/>
                    <strong>
                        Edward S. Hu, Richard Chang, et al. "Planning goals for exploration," ICLR, 2023.
                    </strong>
                    <a href="https://arxiv.org/abs/2303.13002" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>04월 18일 (화) 논문 세미나 – 최호빈
                    <br/>
                    <strong>
                        Vezhnevets, Alexander Sasha, et al., "Feudal networks for hierarchical reinforcement learning," International Conference on Machine Learning (ICML), PMLR, 2017.
                    </strong>
                    <a href="http://proceedings.mlr.press/v70/vezhnevets17a/vezhnevets17a.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>04월 11일 (화) 논문 세미나 – 임현교
                    <br/>
                    <strong>
                        Z. Yuan, G. Li, Z. Wang, J. Sun and R. Cheng, "RL-CSL: A Combinatorial Optimization Method Using Reinforcement Learning and Contrastive Self-Supervised Learning," in IEEE Transactions on Emerging Topics in Computational Intelligence, 2022.
                    </strong>
                    <a href="https://ieeexplore.ieee.org/document/9690950" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>04월 04일 (화) 논문 세미나 – 울라 이산
                    <br/>
                    <strong>
                        L. Wang, K. Wang, C. Pan, W. Xu, N. Aslam and A. Nallanathan, "Deep Reinforcement Learning Based Dynamic Trajectory Control for UAV-Assisted Mobile Edge Computing," in IEEE Transactions on Mobile Computing, 2022.
                    </strong>
                    <a href="https://ieeexplore.ieee.org/abstract/document/9354996?casa_token=izm1qFK4iRwAAAAA:0WdxAHI9sLMY6r4HB56rTLwgd-6LgbHC_FC2NwsroA6RnX5R_2AzrU_lHuaDO2lwfvUhE0ZH3Y4" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>03월 28일 (화) 논문 세미나 – 최요한
                    <br/>
                    <strong>
                        Chen, Lili, et al. "Decision transformer: Reinforcement learning via sequence modeling." NIPS, 2021.
                    </strong>
                    <a href="https://arxiv.org/abs/2106.01345" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>03월 21일 (화) 논문 세미나 – 석영준
                    <br/>
                    <strong>
                        Andrea Skolik, Sofiene Jerbi, Vedran Dunjko, "Quantum agents in the Gym: a variational quantum algorithm for deep Q-learning," 	Quantum 6, 720, 2022.
                    </strong>
                    <a href="https://arxiv.org/pdf/2103.15084v3.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>03월 14일 (화) 논문 세미나 – 지창훈
                    <br/>
                    <strong>
                        H. Huang, Y. Yang, H. Wang, Z. Ding, H. Sari and F. Adachi, "Deep Reinforcement Learning for UAV Navigation Through Massive MIMO Technique," IEEE Transactions on Vehicular Technology, 2020
                    </strong>
                    <a href="https://ieeexplore.ieee.org/document/8894381" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                    <br/>
                    <strong>
                        Yun, Won Joon, et al. "Distributed deep reinforcement learning for autonomous aerial eVTOL mobility in drone taxi applications," ICT Express, 2021
                    </strong>
                    <a href="https://www.sciencedirect.com/science/article/pii/S2405959521000059" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                    <span style="font-family: Arial; font-weight: bold; color: #565656; background: #F8E8FF; box-shadow: 0px 0px 0px 5px #F8E8FF; border: dashed 2px #8A66AE; border-radius: 8px;"><strong>drone</strong></span>
                </li>
                <br/>
                <li>02월 15일 (수) 논문 세미나 – 석영준
                    <br/>
                    <strong>
                        Miralem Mehic, Marcin Niemiec, "Quantum Key Distribution A Networking Perspective,"ACM Computing SurveysVolume 53Issue 5Article No.: 96pp 1–41, 2020.
                    </strong>
                    <a href="https://dl.acm.org/doi/pdf/10.1145/3402192" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>02월 01일 (수) 논문 세미나 – 지창훈
                    <br/>
                    <strong>
                        Y. Song, M. Steinweg, E. Kaufmann and D. Scaramuzza, "Autonomous Drone Racing with Deep Reinforcement Learning," IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2021.
                    </strong>
                    <a href="https://ieeexplore.ieee.org/abstract/document/9636053" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                    <span style="font-family: Arial; font-weight: bold; color: #565656; background: #F8E8FF; box-shadow: 0px 0px 0px 5px #F8E8FF; border: dashed 2px #8A66AE; border-radius: 8px;"><strong>drone</strong></span>
                </li>
                <br/>
                <li>01월 25일 (수) 논문 세미나 – 최호빈
                    <br/>
                    <strong>
                        Tang, Hengliang, et al., "A novel hierarchical soft actor-critic algorithm for multi-logistics robots task allocation," IEEE Access, 2021.
                    </strong>
                    <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9363881&tag=1" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>01월 25일 (수) 논문 세미나 – 지창훈
                    <br/>
                    <strong>
                        Zhou, Xin, et al. "Ego-planner: An esdf-free gradient-based local planner for quadrotors." IEEE Robotics and Automation Letters, 2020.
                    </strong>
                    <a href="https://arxiv.org/abs/2008.08835" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                    <span style="font-family: Arial; font-weight: bold; color: #565656; background: #F8E8FF; box-shadow: 0px 0px 0px 5px #F8E8FF; border: dashed 2px #8A66AE; border-radius: 8px;"><strong>drone</strong></span>
                </li>
                <br/>
                <li>01월 12일 (목) 논문 세미나 – 울라 이산
                    <br/>
                    <strong>
                        Junyoung Park, Jaehyeong Chun, Sang Hun Kim, Youngkook Kim, Jinkyoo Park, "Learning to schedule job-shop problems: Representation and policy learning using graph neural network and reinforcement learning" International Journal of Production Research, 2021.
                    </strong>
                    <a href="https://arxiv.org/abs/2106.01086" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
            </ul>
        </div>
        <button class="accordion">2022</button>
        <div class="panel article-content-1">
            <ul>
                <li>12월 28일 (수) 논문 세미나 – 석영준
                    <br/>
                    <strong>
                        Vinyals, Oriol and Fortunato, Meire and Jaitly, Navdeep, "Pointer Networks," NIPS, 2015.
                    </strong>
                    <a href="https://papers.nips.cc/paper/2015/file/29921001f2f04bd3baee84a12e98098f-Paper.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                    <br/>
                    <strong>
                        Irwan Bello, et al., "Neural Combinatorial Optimization with Reinforcement Learning,", ICLR, 2017.
                    </strong>
                    <a href="https://arxiv.org/pdf/1611.09940.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>12월 21일 (수) 논문 세미나 – 최요한
                    <br/>
                    <strong>
                        Finn, Chelsea, Pieter Abbeel, and Sergey Levine., "Model-agnostic meta-learning for fast adaptation of deep networks.," International conference on machine learning. PMLR, 2017.
                    </strong>
                    <a href="https://arxiv.org/abs/1703.03400" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>12월 15일 (목) 논문 세미나 – 지창훈
                    <br/>
                    <strong>
                        A. Kumar, et al. "Conservative q-learning for offline reinforcement learning," NIPS, 2020
                    </strong>
                    <a href="https://proceedings.neurips.cc/paper/2020/hash/0d2b2061826a5df3221116a5085a6052-Abstract.html" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>12월 09일 (금) 논문 세미나 – 지창훈
                    <br/>
                    <strong>
                        A. Kumar, et al. "Offline Q-Learning on Diverse Multi-Task Data Both Scales And Generalizes," arXiv, 2022
                    </strong>
                    <a href="https://arxiv.org/pdf/2211.15144.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>11월 03일 (목) 논문 세미나 – 최요한
                    <br/>
                    <strong>
                        Wang, Jane X., et al., "LEARNING TO REINFORCEMENT LEARN,", 2017.
                    </strong>
                    <a href="https://arxiv.org/abs/1611.05763?context=cs" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>10월 27일 (목) 논문 세미나 – 석영준
                    <br/>
                    <strong>
                        Ruben Solozabal, "Constrained Combinatorial Optimization with Reinforcement Learning,", 2020.
                    </strong>
                    <a href="https://arxiv.org/pdf/2006.11984.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>10월 20일 (목) 논문 세미나 – 최호빈
                    <br/>
                    <strong>
                        Chenghao Li, et al., "Celebrating Diversity in Shared Multi-Agent Reinforcement Learning," NIPS, 2021.
                    </strong>
                    <a href="https://arxiv.org/pdf/2106.02195.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>10월 13일 (목) 논문 세미나 – 임현교
                    <br/>
                    <strong>
                        J. Cheng, Y. Wu, Y. Lin, Y. E, F. Tang and J. Ge, "VNE-HRL: A Proactive Virtual Network Embedding Algorithm Based on Hierarchical Reinforcement Learning," IEEE Transactions on Network and Service Management, 2021.
                    </strong>
                    <a href="https://ieeexplore.ieee.org/document/9570771" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>09월 30일 (금) 세미나 – 석영준
                    <br/>
                    <strong>
                        windy maze environment of ray
                    </strong>
                    <a href="https://github.com/ray-project/ray/blob/master/rllib/examples/env/windy_maze_env.py" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>09월 22일 (목) 논문 세미나 – 지창훈
                    <br/>
                    <strong>
                        Lucy Xiaoyang Shi, Joseph J. Lim, Youngwoon Lee, "Skill-based Model-based Reinforcement Learning," arXiv, 2022.
                    </strong>
                    <a href="https://arxiv.org/abs/2207.07560" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>09월 01일 (목) 논문 세미나 – 석영준
                    <br/>
                    <strong>
                        Ryan Lowe, Yi Wu, Aviv Tamar, Jean Harb, Pieter Abbeel, Igor Mordatch, "Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments," NeurIPS, 2017
                    </strong>
                    <a href="https://arxiv.org/abs/1706.02275" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>08월 24일 (수) 논문 세미나 – 김주봉
                    <br/>
                    <strong>
                        Nicklas Hansen, Rishabh Jangir, Yu Sun, Guillem Alenya, Pieter Abbeel, Alexei A Efros, Lerrel Pinto, Xiaolong Wang, "Self-Supervised Policy Adaptation During Deployment," ICLR, 2021.
                    </strong>
                    <a href="https://openreview.net/forum?id=o_V-MjyyGV_" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>08월 10일 (수) 논문 세미나 – 석영준
                    <br/>
                    <strong>
                        Mohammadreza Nazari, Afshin Oroojlooy, Lawrence V. Snyder, Martin Takáč, "Reinforcement Learning for Solving the Vehicle Routing Problem," NeurIPS, 2018.
                    </strong>
                    <a href="https://arxiv.org/abs/1802.04240" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>08월 04일 (목) 논문 세미나 – 최요한
                    <br/>
                    <strong>
                        Luiz A. Celiberto Jr., et al., "Using Transfer Learning to Speed-Up Reinforcement Learning: a Cased-Based Approach." 2010 Latin American Robotics Symposium and Intelligent Robotics Meeting. IEEE, 2010.
                    </strong>
                    <a href="https://www.iiia.csic.es/~mantaras/LARS2010.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                    <br/>
                    <strong>
                        Samuel Barrett, Matthew E. Taylor, and Peter Stone, "Transfer Learning for Reinforcement Learning on a Physical Robot," AAMAS, 2010.
                    </strong>
                    <a href="https://www.cs.utexas.edu/~AustinVilla/papers/AAMASWS10-barrett.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                    <a href="https://linklab.s3.ap-northeast-2.amazonaws.com/homepage/seminar/Transfer+Learning+for+RL+in+2010.pdf" target="_blank">
                        <span class="badge badge-info">Presentation</span>
                    </a>
                </li>
                <br/>
                <li>07월 19일 (화) 논문 세미나 – 지창훈
                    <br/>
                    <strong>
                        Jagdeep Singh Bhatia, Holly Jackson, Yunsheng Tian, Jie Xu, Wojciech Matusik, "Evolution Gym: A Large-Scale Benchmark for Evolving Soft Robots," NIPS, 2021.
                    </strong>
                    <a href="https://arxiv.org/abs/2201.09863" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
{#                                                <a href="https://linklab.s3.ap-northeast-2.amazonaws.com/homepage/seminar/evolve+gym.pdf" target="_blank">#}
{#                                                    <span class="badge badge-info">Presentation</span>#}
{#                                                </a>#}
                </li>
                <br/>
                <li>07월 13일 (수) 논문 세미나 – 최호빈
                    <br/>
                    <strong>
                        Wang, Yihan, et al., "Dop: Off-policy multi-agent decomposed policy gradients," ICLR, 2020.
                    </strong>
                    <a href="https://openreview.net/pdf?id=6FqKiVAdI3Y" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                    <a href="https://linklab.s3.ap-northeast-2.amazonaws.com/homepage/seminar/DOP.pdf" target="_blank">
                        <span class="badge badge-info">Presentation</span>
                    </a>
                </li>
                <br/>
                <li>07월 06일 (수) 논문 세미나 – 최요한
                    <br/>
                    <strong>
                        Meng Fang, et al., "Curriculum-guided Hindsight Experience Replay," Advances in Neural Information Processing Systems 32, 2019.
                    </strong>
                    <a href="https://papers.nips.cc/paper/2019/file/83715fd4755b33f9c3958e1a9ee221e1-Paper.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                    <a href="https://linklab.s3.ap-northeast-2.amazonaws.com/homepage/seminar/Curriculum-guided+HER.pdf" target="_blank">
                        <span class="badge badge-info">Presentation</span>
                    </a>
                </li>
                <br/>
                <li>06월 16일 (목) 논문 세미나 – 석영준
                    <br/>
                    <strong>
                        Yang Yang, Yulin Hu, M. Cenk Gursoy, "Deep Reinforcement Learning and Optimization Based Green Mobile Edge Computing
                        ," IEEE 18th Annual Consumer Communications & Networking Conference (CCNC), 2021.
                    </strong>
                    <a href="https://ieeexplore.ieee.org/document/9369566" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                    <br/>
                    <strong>
                        Denis Yarats, Rob Fergus, Alessandro Lazaric, Lerrel Pinto, "Mastering Visual Continuous Control: Improved Data-Augmented Reinforcement Learning," arXiv:2107.09645, 2022.
                    </strong>
                    <a href="https://arxiv.org/abs/2107.09645" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>06월 8일 (수) 논문 세미나 – 울라 이산
                    <br/>
                    <strong>
                        Youn J, Han Y-H, "Intelligent Task Dispatching and Scheduling Using a Deep Q-Network in a Cluster Edge Computing System," Sensors, 2022.
                    </strong>
                    <a href="https://www.mdpi.com/1424-8220/22/11/4098/htm" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>06월 3일 (금) 논문 세미나 – 최호빈
                    <br/>
                    <strong>
                        Hyeoksoo Lee, Jiwoo Hong, and Jongpil Jeong, "MARL-Based Dual Reward Model on Segmented Actions for Multiple Mobile Robots in AutomatedWarehouse Environment," Applied Sciences, 2022.
                    </strong>
                    <a href="https://www.mdpi.com/2076-3417/12/9/4703" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                    <a href="https://linklab.s3.ap-northeast-2.amazonaws.com/homepage/seminar/Dual+Reward+Model+on+Segmented+Actions.pdf" target="_blank">
                        <span class="badge badge-info">Presentation</span>
                    </a>
                </li>
                <br/>
                <li>05월 27일 (금) 논문 세미나 – 장용연
                    <br/>
                    <strong>
                        Alexander C. Li, Lerrel Pinto, Pieter Abbeel, "Generalized Hindsight for Reinforcement Learning," arXiv, 2020.
                    </strong>
                    <a href="https://arxiv.org/abs/2002.11708" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                    <a href="https://linklab.s3.ap-northeast-2.amazonaws.com/homepage/seminar/Generalized+Hindsight.pdf" target="_blank">
                        <span class="badge badge-info">Presentation</span>
                    </a>
                </li>
                <br/>
                <li>05월 18일 (수) 논문 세미나 – 허주성
                    <br/>
                    <strong>
                        Stephan Zheng, Alexander Trott, Sunil Srinivasa, David C. Parkes, Richard Socher, "The AI Economist: Optimal Economic Policy Design via Two-level Deep Reinforcement Learning," https://arxiv.org/abs/2108.02755.
                    </strong>
                    <a href="https://arxiv.org/abs/2108.02755" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>05월 4일 (수) 논문 세미나 – 지창훈, 김주봉
                    <br/>
                    <strong>
                        1) Aravind Srinivas, et al., "CURL: Contrastive Unsupervised Representations for Reinforcement Learning," arXiv, 2020.
                    </strong>
                    <a href="https://arxiv.org/abs/2004.04136" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                    <a href="https://linklab.s3.ap-northeast-2.amazonaws.com/homepage/seminar/CURL.pdf" target="_blank">
                        <span class="badge badge-info">Presentation</span>
                    </a>
                    <br/>
                    <strong>
                        2) Yuri Burda, et al., "Exploration by Random Network Distillation," ICLR, 2019.
                    </strong>
                    <a href="https://openreview.net/forum?id=H1lJJnR5Ym" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>04월 27일 (수) 논문 세미나 – 김주봉, 장용연
                    <br/>
                    <strong>
                        3) New Paper Idea
                    </strong>
                    <br/>
                    <strong>
                        4) Marcin Andrychowicz, et al., "Hindsight Experience Replay," NIPS, 2017.
                    </strong>
                    <a href="https://arxiv.org/abs/1707.01495" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>04월 20일 (수) 논문 세미나 – 울라 이산 (외부 세미나)
                    <br/>
                    <strong>
                        A. Qadeer and M. J. Lee, "DDPG-Edge-Cloud: A Deep-Deterministic Policy Gradient based Multi-Resource Allocation in Edge-Cloud System," 2022 International Conference on Artificial Intelligence in Information and Communication (ICAIIC), 2022.
                    </strong>
                    <a href="https://ieeexplore.ieee.org/document/9722676" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
{#                                                <a href="https://linklab.s3.ap-northeast-2.amazonaws.com/homepage/seminar/TD-MPC.pdf" target="_blank">#}
{#                                                    <span class="badge badge-info">Presentation</span>#}
{#                                                </a>#}
                </li>
                <br/>
                <li>04월 13일 (수) 논문 세미나 – 지창훈
                    <br/>
                    <strong>
                        Nicklas Hansen, Xiaolong Wang, et al. "Temporal Difference Learning for Model Predictive Control." arXiv, 2022.
                    </strong>
                    <a href="https://arxiv.org/abs/2203.04955" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                    <a href="https://linklab.s3.ap-northeast-2.amazonaws.com/homepage/seminar/TD-MPC.pdf" target="_blank">
                        <span class="badge badge-info">Presentation</span>
                    </a>
                </li>
                <br/>
                <li>04월 06일 (수) 논문 세미나 – 석영준
                    <br/>
                    <strong>
                        Sur, Giwon, et al. "A Deep Reinforcement Learning-Based Scheme for Solving Multiple Knapsack Problems." Applied Sciences 12.6 (2022): 3068.
                    </strong>
                    <a href="https://www.mdpi.com/2076-3417/12/6/3068" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                    <a href="https://linklab.s3.ap-northeast-2.amazonaws.com/homepage/seminar/MultiKnapsackProblem.pdf" target="_blank">
                        <span class="badge badge-info">Presentation</span>
                    </a>
                </li>
                <br/>
                <li>03월 30일 (수) 논문 세미나 – 최요한
                    <br/>
                    <strong>
                        Yeo Jin Kim, Min Chi, “Time-Aware Q-Networks: Resolving Temporal Irregularity for Deep Reinforcement Learning,” arXiv, 2021.
                    </strong>
                    <a href="https://arxiv.org/abs/2105.02580" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                    <a href="https://linklab.s3.ap-northeast-2.amazonaws.com/homepage/seminar/Time-Aware+Q-Networks.pdf" target="_blank">
                        <span class="badge badge-info">Presentation</span>
                    </a>
                </li>
                <br/>
                <li>03월 23일 (수) 논문 세미나 – 임현교
                    <br/>
                    <strong>
                        Refaei Afshar, R., Zhang, Y., Firat, M., and Kaymak, U., “A State Aggregation Approach for Solving Knapsack Problem with Deep Reinforcement Learning,” arXiv, 2020.
                    </strong>
                    <a href="https://arxiv.org/pdf/2004.12117.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                    <a href="https://linklab.s3.ap-northeast-2.amazonaws.com/homepage/seminar/A+State+Aggregation+Approach+for+Solving+Knapsack+Problem+with+Deep+Reinforcement+Learning.pdf" target="_blank">
                        <span class="badge badge-info">Presentation</span>
                    </a>
                </li>
                <br/>
                <li>03월 16일 (수) 논문 세미나 – 최호빈
                    <br/>
                    <strong>
                        Chenghao Li, et al., "Celebrating Diversity in Shared Multi-Agent Reinforcement Learning," NIPS, 2021.
                    </strong>
                    <a href="https://arxiv.org/pdf/2106.02195.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                    <a href="https://linklab.s3.ap-northeast-2.amazonaws.com/homepage/seminar/Celebrating+Diversity+in+Shared+Multi-Agent+Reinforcement+Learning.pdf" target="_blank">
                        <span class="badge badge-info">Presentation</span>
                    </a>
                </li>
                <br/>
                <li>03월 10일 (목) 논문 세미나 – 허주성
                    <br/>
                    <strong>
                        Stephan Zheng, et al., "The AI Economist: Improving Equality and Productivity with AI-Driven Tax Policies," https://arxiv.org/abs/2004.13332.
                    </strong>
                    <a href="https://arxiv.org/abs/2004.13332" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>03월 03일 (목) 논문 세미나 – 김주봉
                    <br/>
                    <strong>
                        Irwan Bello, et al., "Neural Combinatorial Optimization with Reinforcement Learning,", ICLR, 2017.
                    </strong>
                    <a href="https://arxiv.org/pdf/1611.09940.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                    <br/>
                    <strong>
                        Thomas D. Barrett, et al., "Exploratory Combinatorial Optimization with Reinforcement Learning,", AAAI, 2020.
                    </strong>
                    <a href="https://arxiv.org/pdf/1909.04063.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                    <br/>
                    <strong>
                        Ofir Nachum, et al., "Data-Efficient Hierarchical Reinforcement Learning,", NIPS, 2018.
                    </strong>
                    <a href="https://arxiv.org/pdf/1805.08296.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>02월 24일 (목) 논문 세미나 – 최요한
                    <br/>
                    <strong>
                        Marcin Andrychowicz, et al., "Hindsight Experience Replay," NIPS, 2017.
                    </strong>
                    <a href="https://arxiv.org/abs/1707.01495" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                    <a href="https://linklab.s3.ap-northeast-2.amazonaws.com/homepage/seminar/Hindsight+Experience+Replay.pdf" target="_blank">
                        <span class="badge badge-info">Presentation</span>
                    </a>
                </li>
                <br/>
                <li>02월 15일 (화) 논문 세미나 – 울라 이산
                    <br/>
                    <strong>
                        F. Qi, L. Zhuo and C. Xin, "Deep Reinforcement Learning Based Task Scheduling in Edge Computing Networks," 2020 IEEE/CIC International Conference on Communications in China (ICCC), pp. 835-840, 2020.
                    </strong>
                    <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9238937" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                    <a href="https://linklab.s3.ap-northeast-2.amazonaws.com/homepage/seminar/1.-Deep-Reinforcement-Learning-Based-Task-Scheduling-in-Edge-Computing-Networks.pdf" target="_blank">
                        <span class="badge badge-info">Presentation</span>
                    </a>
                </li>
                <br/>
                <li>02월 08일 (화) 논문 세미나 – 석영준
                    <br/>
                    <strong>
                        RL — Policy Gradient Explained (Part I & II)
                    </strong>
                    <a href="https://jonathan-hui.medium.com/rl-policy-gradients-explained-9b13b688b146" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                    <a href="https://jonathan-hui.medium.com/rl-policy-gradients-explained-advanced-topic-20c2b81a9a8b" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                    <a href="https://linklab.s3.ap-northeast-2.amazonaws.com/homepage/seminar/PolicyGradient_0208.pdf" target="_blank">
                        <span class="badge badge-info">Presentation</span>
                    </a>
                </li>
                <br/>
                <li>01월 25일 (화) 논문 세미나 – 임현교
                    <br/>
                    <strong>
                        H. Huang et al., "Scalable Orchestration of Service Function Chains in NFV-Enabled Networks: A Federated Reinforcement Learning Approach," in IEEE Journal on Selected Areas in Communications, vol. 39, no. 8, pp. 2558-2571, Aug. 2021.
                    </strong>
                    <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9468364" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                    <a href="https://linklab.s3.ap-northeast-2.amazonaws.com/homepage/seminar/Scalable+Orchestration+of+Service+Function+Chains+in+NFV-Enabled+Networks-+A+Federated+Reinforcement+Learning+Approach.pdf" target="_blank">
                        <span class="badge badge-info">Presentation</span>
                    </a>
                </li>
                <br/>
                <li>01월 18일 (화) 논문 세미나 – 지창훈
                    <br/>
                    <strong>
                        Weirui Ye, et al., "Mastering Atari Games with Limited Data," NIPS, 2021.
                    </strong>
                    <a href="https://arxiv.org/abs/2111.00210" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>01월 04일 (화) 논문 세미나 – 최요한
                    <br/>
                    <strong>
                        Junhyuk Oh, Satinder Singh, and Honglak Lee, "Value Prediction Network," NIPS, 2017.
                    </strong>
                    <a href="https://arxiv.org/abs/1707.03497" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                    <a href="https://linklab.s3.ap-northeast-2.amazonaws.com/homepage/seminar/Value+Prediction+Network.pdf" target="_blank">
                        <span class="badge badge-info">Presentation</span>
                    </a>
                </li>
            </ul>
        </div>
        <button class="accordion">2021</button>
        <div class="panel article-content-1">
            <ul>
                <li>12월 28일 (화) 논문 세미나 – 울라 이산
                    <br/>
                    <strong>
                        Taihui Li, et al., "An End-to-End Network Slicing Algorithm Based on Deep Q-Learning for 5G Network
                        ," IEEE Access, July 2020.
                    </strong>
                    <a href="https://ieeexplore.ieee.org/abstract/document/9131779" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>12월 21일 (화) 논문 세미나 – 최호빈
                    <br/>
                    <strong>
                        Gupta, Tarun, et al., "Uneven: Universal value exploration for multi-agent reinforcement learning," International Conference on Machine Learning. PMLR, 2021.
                    </strong>
                    <a href="http://proceedings.mlr.press/v139/gupta21a/gupta21a.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>12월 14일 (화) 논문 세미나 – 지창훈
                    <br/>
                    <strong>
                        Cameron Browne et al., "A Survey of Monte Carlo Tree Search Methods," IEEE Transactions on Computational Intelligence and AI in Games, Vol. 4, No. 1, March 2012.
                    </strong>
                    <a href="https://ieeexplore.ieee.org/document/6145622" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>12월 07일 (화) 논문 세미나 – 김주봉
                    <br/>
                    <strong>
                    Woojun Kim, Jongeui Park, Youngchul Sung, "Communication in Multi-Agent Reinforcement Learning-Intention Sharing," ICLR, 2021.
                    </strong>
                    <a href="https://openreview.net/pdf?id=qpsl2dR9twy" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>11월 30일 (화) 논문 세미나 – 지창훈
                    <br/>
                    <strong>
                    Levine, Sergey, et al., "Offline reinforcement learning: Tutorial, review, and perspectives on open problems.", arXiv preprint arXiv, 2020
                    </strong>
                    <a href="https://arxiv.org/abs/2005.01643" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>11월 23일 (화) 논문 세미나 – 울라 이산
                    <br/>
                    <strong>
                    Lu Zhang, et al., "Task Offloading and Trajectory Control for UAV-Assisted Mobile Edge Computing Using Deep Reinforcement Learning," IEEE ACCESS, 2021.
                    </strong>
                    <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9395130" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>11월 16일 (화) 논문 세미나 – 최요한
                    <br/>
                    <strong>
                    Marc G. Bellemare, Will Dabney, and Remi Munos, "A Distributional Perspective on Reinforcement Learning," ICML, 2017.
                    </strong>
                    <a href="https://arxiv.org/pdf/1707.06887.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>10월 26일 (화) 논문 세미나 – 최호빈
                    <br/>
                    <strong>
                    Lowe, Ryan, et al., "Multi-agent actor-critic for mixed cooperative-competitive environments," NIPS, 2017.
                    </strong>
                    <a href="https://proceedings.neurips.cc/paper/2017/file/68a9750337a418a86fe06c1991a1d64c-Paper.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>10월 19일 (화) 논문 세미나 – 김주봉
                    <br/>
                    <strong>
                    Jianhao Wang, Zhizhou Ren, Terry Liu, Yang Yu, Chongjie Zhang, "QPLEX: DUPLEX DUELING MULTI-AGENT Q-LEARNING," ICLR, 2021.
                    </strong>
                    <a href="https://arxiv.org/pdf/2008.01062v3.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>10월 12일 (화) 논문 세미나 – 지창훈
                    <br/>
                    <strong>
                    Richard S. Sutton. “Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming.” Machine learning proceedings 1990. Morgan Kaufmann, 1990.
                    </strong>
                    <a href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.51.7362&rep=rep1&type=pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                    <br/>
                    <strong>
                    Richard S. Sutton. “Dyna, an Integrated Architecture for Learning, Planning, and Reacting.” ACM Sigart Bulletin, 1991.
                    </strong>
                    <a href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.48.6005&rep=rep1&type=pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>10월 05일 (화) 논문 세미나 – 울라 이산
                    <br/>
                    <strong>
                    P. Zhang, et al., "Dynamic Virtual Network Embedding Algorithm based on Graph Convolution Neural Network and Reinforcement Learning,"  IEEE Internet of Things Journal, 2021.
                    </strong>
                    <a href="https://ieeexplore.ieee.org/document/9475485" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>09월 28일 (화) 논문 세미나 – 최요한
                    <br/>
                    <strong>
                    Hanjun Dai, et al., "Learning Combinatorial Optimization Algorithms over Graphs," NIPS, 2017.
                    </strong>
                    <a href="https://arxiv.org/pdf/1704.01665.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>09월 14일 (화) 논문 세미나 – 최요한
                    <br/>
                    <strong>
                    Ziyu Wang, et al., "Dueling Network Architectures for Deep Reinforcement Learning." International Conference on Machine Learning. PMLR, 2016.
                    </strong>
                    <a href="http://proceedings.mlr.press/v48/wangf16.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>09월 07일 (화) 논문 세미나 – 김주봉
                    <br/>
                    <strong>
                    Chao Yu, Akash Velu, Eugene Vinitsky, Yu Wang, Alexandre Bayen, "The Surprising Effectiveness of PPO in Cooperative Multi-Agent Games," arXiv preprint arXiv:2103.01955, 2021.
                    </strong>
                    <a href="https://arxiv.org/pdf/2103.01955.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>08월 30일 (월) 논문 세미나 – 지창훈
                    <br/>
                    <strong>
                    Hamid Ali, Hammad Majeed, Imran Usman, Khaled A. Almejalli. “Reducing Entropy Overestimation in Soft Actor Critic Using Dual Policy Network.” Hindawi, 2021.
                    </strong>
                    <a href="https://www.hindawi.com/journals/wcmc/2021/9920591/" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>08월 23일 (월) 논문 세미나 – 울라 이산
                    <br/>
                    <strong>
                    Yi, Mengjie, Xijun Wang, Juan Liu, Yan Zhang and B. Bai. “Deep Reinforcement Learning for Fresh Data Collection in UAV-assisted IoT Networks.” IEEE INFOCOM, pp. 716-721, 2020.
                    </strong>
                    <a href="https://arxiv.org/pdf/2003.00391.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>08월 09일 (월) 논문 세미나 – 임현교
                    <br/>
                    <strong>
                    N. Navid, F. Hung, S. Soleyman and D. Khosla. “Graph Convolutional Value Decomposition in Multi-Agent Reinforcement Learning.” ArXiv abs/2010.04740, 2020.
                    </strong>
                    <a href="https://arxiv.org/pdf/2010.04740.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>08월 02일 (월) 논문 세미나 – 김주봉
                    <br/>
                    <strong>
                    T. Wang, T. Gupta, A. Mahajan, B. Peng, S. Whiteson, C. Zhang, "RODE: LEARNING ROLES TO DECOMPOSE MULTI-AGENT TASKS," arXiv preprint arXiv:2010.01523, 2020.
                    </strong>
                    <a href="https://arxiv.org/pdf/2010.01523.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>07월 26일 (월) 논문 세미나 – 울라 이산
                    <br/>
                    <strong>
                    Omar Bouhamed et. al., "A UAV-Assisted Data Collection for Wireless Sensor Networks: Autonomous Navigation and Scheduling," IEEE Access, 2020.
                    </strong>
                    <a href="https://ieeexplore.ieee.org/document/9117104" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>07월 19일 (월) 논문 세미나 – 최호빈
                    <br/>
                    <strong>
                    Huang, Shengyi, and Santiago Ontañón, "A closer look at invalid action masking in policy gradient algorithms," arXiv preprint arXiv:2006.14171, 2020.
                    </strong>
                    <a href="https://arxiv.org/pdf/2006.14171.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>07월 12일 (월) 논문 세미나 – 지창훈
                    <br/>
                    <strong>
                    Kulkarni, Tejas D., et al., "Hierarchical deep reinforcement learning: Integrating temporal abstraction and intrinsic motivation," Advances in neural information processing systems, 2016.
                    </strong>
                    <a href="https://arxiv.org/abs/1604.06057" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>06월 28일 (월) 논문 세미나 – 최요한
                    <br/>
                    <strong>
                        Richard S. Sutton, et. al., "Policy Gradient Methods for Reinforcement Learning with Function Approximation," NIPS, 1999.
                    </strong>
                    <a href="https://proceedings.neurips.cc/paper/1999/file/464d828b85b0bed98e80ade0a5c43b0f-Paper.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>06월 21일 (월) 논문 세미나 – 지창훈
                    <br/>
                    <strong>
                        Pathak, Deepak, et al., "Curiosity-driven exploration by self-supervised prediction," International Conference on Machine Learning. PMLR, 2017.
                    </strong>
                    <a href="https://arxiv.org/pdf/1705.05363.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>06월 14일 (월) 논문 세미나 – 임현교
                    <br/>
                    <strong>
                         A. Rkhami, et al., "On the Use of Graph Neural Networks for Virtual Network Embedding," 2020 International Symposium on Networks, Computers and Communications (ISNCC), 2020.
                    </strong>
                    <a href="https://ieeexplore.ieee.org/abstract/document/9297270" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>05월 31일 (월) 논문 세미나 – 김주봉
                    <br/>
                    <strong>
                         Qiang Ma, et al., "Combinatorial Optimization by Graph Pointer Networks and Hierarchical Reinforcement Learning," arXiv:1911.04936, 2019.</strong>
                    <a href="https://arxiv.org/pdf/1911.04936.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                    <br/>
                    <strong>
                         Vaswani A., et al., "Attention Is All You Need," NIPS, 2017.</strong>
                    <a href="https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                    <br/>
                    <strong>
                         Vinyals, Oriol and Fortunato, Meire and Jaitly, Navdeep, "Pointer Networks," NIPS, 2015.</strong>
                    <a href="https://papers.nips.cc/paper/2015/file/29921001f2f04bd3baee84a12e98098f-Paper.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>05월 24일 (월) 논문 세미나 – 최호빈
                    <br/>
                    <strong>
                         Tang, Hengliang, et al., "A novel hierarchical soft actor-critic algorithm for multi-logistics robots task allocation," IEEE Access, 2021.</strong>
                    <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9363881" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>05월 20일 (목) 논문 세미나 – 임현교
                    <br/>
                    <strong>
                        Wang, Cong, et al. "Modeling on Virtual Network Embedding Using Reinforcement Learning," Concurrency and Computation: Practice and Experience, 2020.
                    </strong>
                    <a href="https://onlinelibrary.wiley.com/doi/full/10.1002/cpe.6020" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                    <br/>
                    <strong>
                        H. Yao, S. Ma, J. Wang, P. Zhang, C. Jiang and S. Guo, "A Continuous-Decision Virtual Network Embedding Scheme Relying on Reinforcement Learning," in IEEE Transactions on Network and Service Management, 2020.
                    </strong>
                    <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8982091" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>05월 12일 (수) 논문 세미나 – 지창훈
                    <br/>
                    <strong>
                         Junta Wu and Huiyun Li, "Deep Ensemble Reinforcement Learning with Multiple DeepDeterministic Policy Gradient Algorithm" Hindawi, 2020.</strong>
                    <a href="https://downloads.hindawi.com/journals/mpe/2020/4275623.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>05월 03일 (월) 논문 세미나 – 김주봉
                    <br/>
                    <strong>
                         Shariq Iqbal, et al., "RANDOMIZED ENTITY-WISE FACTORIZATION FOR MULTI-AGENT REINFORCEMENT LEARNING," arXiv:2006.04222, 2020.</strong>
                    <a href="https://arxiv.org/abs/2006.04222" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>04월 05일 (월) 논문 세미나 – 임현교
                    <br/>
                    <strong>
                         H. Yao, X. Chen, P. Zhang and L. Wang, "A novel reinforcement learning algorithm for virtual network embedding," Neurocomputing, 2018.</strong>
                    <a href="https://www.sciencedirect.com/science/article/pii/S0925231218300420" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>03월 22일 (월) 논문 세미나 – 김주봉
                    <br/>
                    <strong>
                         Tabish Rashid, Gregory Farquhar, Bei Peng, Shimon Whiteson, "Weighted QMIX: Expanding Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning," NIPS, 2020.</strong>
                    <a href="https://proceedings.neurips.cc/paper/2020/file/73a427badebe0e32caa2e1fc7530b7f3-Paper.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>03월 15일 (월) 논문 세미나 – 최호빈
                    <br/>
                    <strong>
                         Christianos, Filippos, Lukas Schäfer, and Stefano V. Albrecht, "Shared Experience Actor-Critic for Multi-Agent Reinforcement Learning," arXiv preprint arXiv:2006.07169, 2020.</strong>
                    <a href="https://arxiv.org/pdf/2006.07169.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>03월 08일 (월) 논문 세미나 – 지창훈
                    <br/>
                    <strong>
                         Scott Fujimoto, et al., "Addressing Function Approximation Error in Actor-Critic Methods", International Conference on Machine Learning, 2018.</strong>
                    <a href="https://arxiv.org/pdf/1802.09477.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>03월 02일 (화) 논문 세미나 – 임현교
                    <br/>
                    <strong>
                         Z. Yan, et al., "Automatic Virtual Network Embedding: A Deep Reinforcement Learning Approach With Graph Convolutional Networks," IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS, Vol. 38, No. 6, June, 2020.</strong>
                    <a href="https://ieeexplore.ieee.org/document/9060910" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>02월 08일 (월) 논문 세미나 – 울라 이산
                    <br/>
                    <strong>
                         Khoa Nguyen, et al., "Efficient Virtual Network Embedding with Node Ranking and Intelligent Link Mapping," IEEE 9th International Conference on Cloud Networking (CloudNet), November, 2020.</strong>
                    <a href="https://cloudnet2020.ieee-cloudnet.org/wp-content/uploads/sites/237/2020/11/TS1-P1.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>02월 01일 (월) 논문 세미나 – 김주봉
                    <br/>
                    <strong>
                         Yong Liu, et al., "Multi-Agent Game Abstraction via Graph Attention Neural Network," AAAI, 2020.</strong>
                    <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.307.716&rep=rep1&type=pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>01월 25일 (월) 논문 세미나 – 최호빈
                    <br/>
                    <strong>
                         Enright, John J., and Peter R. Wurman, "Optimization and coordinated autonomy in mobile fulfillment systems," Workshops at the twenty-fifth AAAI conference on artificial intelligence, 2011.</strong>
                    <a href="https://arxiv.org/abs/1911.10715" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>01월 27일 (수) 논문 세미나 – 울라 이산
                    <br/>
                    <strong>
                         Min Feng, et al., "Virtual Network Embedding based on Modified Genetic Algorithm," Peer-to-Peer Networking and Applications, October 2019.</strong>
                    <a href="https://www.researchgate.net/profile/Peiying_Zhang/publication/320385856_Virtual_network_embedding_based_on_modified_genetic_algorithm/links/5a729ee0458515512075f47d/Virtual-network-embedding-based-on-modified-genetic-algorithm.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>01월 18일 (월) 논문 세미나 – 지창훈
                    <br/>
                    <strong>
                         Mohammed Hossny, et al., "Refined Continuous Control of DDPG Actors via Parametrised Activation," arXiv:2006.02818, June 2020.</strong>
                    <a href="https://arxiv.org/abs/2006.02818" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>01월 11일 (월) 논문 세미나 – 임현교
                    <br/>
                    <strong>
                         Mosharaf Chowdhury, et al., "ViNEYard: Virtual Network Embedding Algorithms With Coordinated Node and Link Mapping," IEEE/ACM TRANSACTIONS ON NETWORKING, VOL. 20, NO. 1, FEBRUARY 2012.</strong>
                    <a href="https://ieeexplore.ieee.org/document/5951812" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>01월 04일 (월) 논문 세미나 – 황규영
                    <br/>
                    <strong>
                         Tuomas Haarnoja, et al., "Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor," ICML 2018.</strong>
                    <a href="https://arxiv.org/abs/1801.01290" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
            </ul>
        </div>
        <button class="accordion">2020</button>
        <div class="panel article-content-1">
            <ul>
                <li>12월 21일 (화) 논문 세미나 – 최호빈, 김주봉
                    <br/>
                    <strong>
                         Anuj Mahajan, et al., "MAVEN: Multi-Agent Variational Exploration," NeurIPS, 7611-7622, 2019.</strong>
                    <a href="https://papers.nips.cc/paper/2019/file/f816dc0acface7498e10496222e9db10-Paper.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>12월 14일 (월) 논문 세미나 – 울라 이산
                    <br/>
                    <strong>
                         M. Feng, et al., "Topology-Aware Virtual Network Embedding Through the Degree," National Doctoral Academic Forum on Information and Communications Technology 2013, Aug, 2013.</strong>
                    <a href="https://ieeexplore.ieee.org/document/6767296" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>11월 16일 (월) 논문 세미나 – 임현교
                    <br/>
                    <strong>
                         Fengsheng Wei et al., “Network Slice Reconfiguration by Exploiting Deep Reinforcement Learning with Large Action Space,”  IEEE Transactions on Network and Service Management, 2020.</strong>
                    <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9177109" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>11월 09일 (월) 논문 세미나 – 김주봉
                    <br/>
                    <strong>
                        Kyunghwan Son et al., “QTRAN: Learning to Factorize with Transformation for Cooperative Multi-Agent Reinforcement learning,” Proceedings of the 36th International Conference on Machine Learning, 2019.</strong>
                    <a href="https://arxiv.org/pdf/1905.05408.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>11월 02일 (월) 논문 세미나 – 울라 이산
                    <br/>
                    <strong>
                        Haozhe Wanga et al., “Data-driven dynamic resource scheduling for network slicing: A Deep reinforcement learning approach,” Information Sciences, 498, pp. 106-116, 2019.</strong>
                    <a href="https://www.sciencedirect.com/science/article/pii/S0020025519303986" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>10월 19일 (월) 논문 세미나 – 지창훈
                    <br/>
                    <strong>
                        S. Vassilaras et al., “Applying Deep Learning and Reinforcement Learning to Traveling Salesman Problem” in IEEE International Conference on Systems, Man, and Cybernetics(SMC). Aug .2018.</strong>
                    <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8659266"
                       target="_blank">
                        <img src="/assets/images/external_link.png"
                             style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                </br>
                <li>10월 05일 (월) 논문 세미나 – 임현교
                    <br/>
                    <strong>
                        S. Vassilaras et al., “The Algorithmic Aspects of Network Slicing,” in IEEE Communications Magazine, vol. 55, no. 8, pp. 112-119, Aug. 2017.</strong>
                    <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8004165&tag=1"
                       target="_blank">
                        <img src="/assets/images/external_link.png"
                             style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>09월 28일 (월) 논문 세미나 – 김주봉
                    <br/>
                    <strong>
                        Yuki Miyashita and Toshiharu Sugawara, “Analysis of coordinated behavior structures with multi-agent deep reinforcement learning,”, Applied Intelligence, 2020.</strong>
                    <a href="https://link.springer.com/content/pdf/10.1007/s10489-020-01832-y.pdf"
                       target="_blank">
                        <img src="/assets/images/external_link.png"
                             style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>09월 21일 (월) 논문 세미나 – 지창훈
                    <br/>
                    <strong>Galina L. Rogova, Jyotsna Kasturi, "Reinforcement Learning Neural Network For Distributed Decision Making",2002</strong>
                    <a href=https://www.researchgate.net/publication/228559072_Reinforcement_learning_neural_network_for_distributed_decision_making
                       target="_blank">
                        <img src="/assets/images/external_link.png"
                             style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>09월 14일 (월) 논문 세미나 – 임현교
                    <br/>
                    <strong>J. Du, X. Huang, F. Wu and S. Leng, "Reinforcement Learning Empowered QoS-aware Adaptive Q-Routing in Ad-hoc Networks," 2020 International Wireless Communications and Mobile Computing (IWCMC), Limassol, Cyprus, pp. 551-556, 2020.</strong>
                    <a href=https://ieeexplore.ieee.org/document/9148532
                       target="_blank">
                        <img src="/assets/images/external_link.png"
                             style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>09월 07일 (월) 논문 세미나 – 최호빈
                    <br/>
                    <strong>Yali Du, Lei Han, Meng Fang, Tianhong Dai, Ji Liu, Dacheng Tao, "LIIR: Learning Individual Intrinsic Reward in Multi-Agent Reinforcement Learning," NIPS, 2019.</strong>
                    <a href="https://papers.nips.cc/paper/8691-liir-learning-individual-intrinsic-reward-in-multi-agent-reinforcement-learning.pdf"
                       target="_blank">
                        <img src="/assets/images/external_link.png"
                             style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>07월 30일 (목) 논문 세미나 – 임현교
                    <br/>
                    <strong>Q. Fu, E. Sun, K. Meng, M. Li and Y. Zhang, "Deep Q-Learning for Routing Schemes in SDN-Based Data Center Networks,"
                    in IEEE Access, vol. 8, pp. 103491-103499, 2020.</strong>
                    <a href="https://ieeexplore.ieee.org/document/9105030"
                       target="_blank">
                        <img src="/assets/images/external_link.png"
                             style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li>07월 23일 (목) 논문 세미나 – 황규영
                    <br/>
                    <strong>Ian Osband, Charles Blundell, Alexander Pritzel, Benjamin Van Roy, “Deep Exploration via Bootstrapped DQN,”
                    Advances in Neural Information Processing Systems 29 (NIPS 2016).</strong>
                    <a href="https://papers.nips.cc/paper/6501-deep-exploration-via-bootstrapped-dqn"
                       target="_blank">
                        <img src="/assets/images/external_link.png"
                             style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
            <br/>
            <li>02월 17일 (월) 논문 세미나 – 최호빈
                <br/>
                <strong>Zäzilia Seibold, Thomas Stoll, Kai Furmans, “Layout-optimized
                    sorting of
                    goods with decentralized controlled conveying modules,” 2013
                    IEEE International Systems Conference (SysCon), Apr. 2013.</strong>
                <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6549948"
                   target="_blank">
                    <img src="/assets/images/external_link.png"
                         style="width: 1.5em;vertical-align:middle;"/>
                </a>
            </li>
            <br/>
            <li>02월 11일 (화) 논문 세미나 – 김주봉
                <br/>
                <strong>
                    T. Eccles et al., “Biases for Emergent Communication in Multi-agent
                    Reinforcement Learning,”, NIPS, 2019.</strong>
                <a href="https://papers.nips.cc/paper/9470-biases-for-emergent-communication-in-multi-agent-reinforcement-learning.pdf"
                   target="_blank">
                    <img src="/assets/images/external_link.png"
                         style="width: 1.5em;vertical-align:middle;"/>
                </a>
            </li>
            <br/>
            <li>02월 03일 (월) 교재 세미나 – 황규영
                <br/>
                <strong>Richard S. Sutton and Andrew G. Barto, “Reinforcement Learning: An
                    Introduction,” second edition, MIT Press, Cambridge, MA,
                    2018.</strong>
                <a href="http://incompleteideas.net/book/RLbook2018.pdf"
                   target="_blank">
                    <img src="/assets/images/external_link.png"
                         style="width: 1.5em;vertical-align:middle;"/>
                </a>
            </li>
            <br/>
            <li>01월 20일 (월) 논문 세미나 – 임현교</p>
                <ul>
                    <li>논문: <a
                            href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8791693">C.
                        Nadiger, A. Kumar and S. Abdelhak, “Federated Reinforcement
                        Learning for Fast Personalization,” 2019 IEEE Second
                        International Conference on Artificial Intelligence and
                        Knowledge Engineering (AIKE), Sardinia, Italy, pp. 123-127,
                        2019.</a></li>
                </ul>
            </li>
            <br/>
            <li>01월 17일 (금) 논문 세미나 – 황규영
                <br/>
                <strong>Matteo Hessel, Joseph Modayil, Hado van Hasselt, Tom Schaul, Georg
                    Ostrovski, Will Dabney, Dan Horgan, Bilal Piot, Mohammad Azar,
                    David Silver, “Rainbow: Combining Improvements in Deep
                    Reinforcement Learning,” AAAI, 2018.</strong>
                <a href="https://pdfs.semanticscholar.org/75e5/b72cf0eb3c1531ec241e6ca8a4308a70f147.pdf"
                   target="_blank">
                    <img src="/assets/images/external_link.png"
                         style="width: 1.5em;vertical-align:middle;"/>
                </a>
            </li>
            <br/>
            <li>01월 06일 (월) 논문 세미나 – 최호빈</p>
                <ul>
                    <li>논문: <a href="https://arxiv.org/pdf/1812.00285.pdf">Sanmit
                        Narvekar, Peter Stone, “Learning Curriculum Policies for
                        Reinforcement Learning,” arXiv:1812.00285, 2018.</a></li>
                </ul>
            </li>
        </ul>
    </div>
</article>
<br/>
<article>
    <button class="accordion">2019</button>
    <div class="panel article-content-1">
        <ul>
            <li>12월 30일 (월) 논문 세미나 – 김주봉<br/>
                <strong>
                    David Silver, Guy Lever, Nicolas Heess, Thomas Degris, Daan
                    Wierstra,
                    Martin Riedmiller, “Deterministic Policy Gradient Algorithms,”
                    JMLR, 2014.
                    <a href="http://proceedings.mlr.press/v32/silver14.pdf"
                       target="_blank">
                        <img src="/assets/images/external_link.png"
                             style="width: 1.5em;vertical-align:middle;"/>
                    </a> &amp;
                    <a href="http://proceedings.mlr.press/v32/silver14-supp.pdf">Appendix</a>
                </strong>
                <br/>
                <strong>
                    Timothy P.
                    Lillicrap∗, Jonathan J. Hunt∗, Alexander Pritzel, Nicolas Heess,
                    Tom Erez, Yuval Tassa, David Silver &amp; Daan Wierstra,
                    “CONTINUOUS CONTROL WITH DEEP REINFORCEMENT LEARNING,” ICLR,
                    2016.
                </strong>
                <a href="https://arxiv.org/pdf/1509.02971.pdf" target="_blank"><img
                        src="/assets/images/external_link.png"
                        style="width: 1.5em;vertical-align:middle;"/></a>
            </li>
            <br/>
            <li>
                12월 23일 (월) 논문 세미나 – 임현교
                <br/>
                <strong>Horgan, Dan,
                    John Quan, David Budden, Gabriel Barth-Maron, Matteo Hessel,
                    Hado van Hasselt and David Silver. “Distributed Prioritized
                    Experience Replay.” ArXiv abs/1803.00933, 2018.</strong>
                <a href="https://arxiv.org/pdf/1803.00933.pdf" target="_blank"><img
                        src="/assets/images/external_link.png"
                        style="width: 1.5em;vertical-align:middle;"/></a>
            </li>
            <br/>
            <li>
                <p>12월 16일 (월) 논문 세미나 – 임현교</p>
                <ul>
                    <li>논문: <a href="https://arxiv.org/pdf/1507.04296.pdf">Nair, Arun,
                        Praveen Srinivasan, Sam Blackwell, Cagdas Alcicek, Rory Fearon,
                        Alessandro De Maria, Vedavyas Panneershelvam, Mustafa Suleyman,
                        Charles Beattie, Stig Petersen, Shane Legg, Volodymyr Mnih,
                        Koray Kavukcuoglu and David Silver. “Massively Parallel Methods
                        for Deep Reinforcement Learning.” ArXiv abs/1507.04296,
                        2015.</a></li>
                </ul>
            </li>
            <br/>
            <li>
                <p>11월 18일 (월) 논문 세미나 – 임현교</p>
                <ul>
                    <li>논문: <a href="https://arxiv.org/pdf/1910.04041.pdf">Ramy E. Ali,
                        Bilgehan Erman, Ejder Ba¸stug and Bruce Cilli, “Hierarchical
                        Deep Double Q-Routing,” arXiv:1910.04041, 9 Oct. 2019.</a></li>
                </ul>
            </li>
            <li>
                <p>11월 11일 (월) 논문 세미나 – 최호빈</p>
                <ul>
                    <li>논문: <a
                            href="https://ronan.collobert.com/pub/matos/2009_curriculum_icml.pdf">Yoshua
                        Bengio, Jerome Louradour, Ronan Collobert, Jason Weston,
                        “Curriculum Learning,” ICML, 2009.</a></li>
                </ul>
            </li>
            <li>
                <p>11월 04일 (월) 논문 세미나 – 김주봉</p>
                <ul>
                    <li>논문: <a href="https://arxiv.org/pdf/1712.07893.pdf">Zhang-Wei
                        Hong, Shih-Yang Su, Tzu-Yun Shann, Yi-Hsiang Chang, Chun-Yi Lee
                        , “A Deep Policy Inference Q-Network for Multi-Agent Systems,”
                        arXiv:1712.07893, 9 Apr. 2018.</a></li>
                </ul>
            </li>
            <br/>
            <li>10월 14일 (월) 논문 세미나 – 황규영
                <br/>
                <strong>Efe Camci, Erdal Kayacan, “End-to-End Motion Planning of Quadrotors
                    Using
                    Deep Reinforcement Learning,” arXiv:1909.13599v1, 30 Sep 2019.</strong>
                <a href="https://arxiv.org/pdf/1909.13599.pdf"
                   target="_blank">
                    <img src="/assets/images/external_link.png"
                         style="width: 1.5em;vertical-align:middle;"/>
                </a>
            </li>
            <br/>
            <li>10월 07일 (월) 논문 세미나 – 황규영
                <br/>
                <strong>Iñaki Iturrate, Ricardo Chavarriaga, Luis Montesano, Javier Minguez,
                    José del R. Millán, “Teaching brain-machine interfaces as an
                    alternative paradigm to neuroprosthetics control,” nature
                    Scientific Reports, 2015.</strong>
                <a href="https://www.nature.com/articles/srep13893"
                   target="_blank">
                    <img src="/assets/images/external_link.png"
                         style="width: 1.5em;vertical-align:middle;"/>
                </a>
            </li>
            <br/>
            <li>
                <p>09월 30일 (월) 논문 세미나 – 김주봉</p>
                <ul>
                    <li>논문: <a href="https://arxiv.org/pdf/1909.07528.pdf">Bowen Baker,
                        “EMERGENT TOOL USE FROM MULTI-AGENT AUTOCURRICULA,”
                        arXiv:1909.07528v1, 2019.</a></li>
                    <li>발표자료</li>
                </ul>
            </li>
            <li>
                <p>09월 04일 (수) 논문 세미나 – 김주봉</p>
                <ul>
                    <li>논문: <a
                            href="https://papers.nips.cc/paper/6391-generative-adversarial-imitation-learning.pdf">Jonathan
                        Ho, Stefano Ermon, “Generative Adversarial Imitation Learning,”
                        30th Conference on Neural Information Processing Systems (NIPS
                        2016), Barcelona, Spain.</a></li>
                    <li>발표자료</li>
                </ul>
            </li>
            <li>
                <p>06월 25일 (화) 논문 세미나 – 최호빈</p>
                <ul>
                    <li><a href="https://ieeexplore.ieee.org/document/8715232">James C.
                        Chen, et al., “Solving a Sortation Conveyor Layout Design
                        Problem with Simulation-optimization Approach,” 2019 IEEE 6th
                        International Conference on Industrial Engineering and
                        Applications (ICIEA), 2019</a></li>
                    <li><a href="https://ieeexplore.ieee.org/document/640965/">A.
                        Jayaraman, et al., “A Sortation System Model,” Winter Simulation
                        Conference Proceedings, 1997</a></li>
                    <li>
                        <a href="https://pdfs.semanticscholar.org/e73b/08d2fed65fbf93e45aeb9928077112baf9e5.pdf">Fu-bin
                            Pan, “Simulation Design of Express Sorting System—Example of
                            SF’s Sorting Center,” The Open Cybernetics &amp; Systemics
                            Journal, 8, 1116-1122, 2014</a></li>
                    <li><a href="https://ieeexplore.ieee.org/document/8588572">Samuel
                        Chenatti, et al., “Deep Reinforcement Learning in Robotics
                        Logistic Task Coordination,” 2018 Latin American Robotic
                        Symposium, 2018</a></li>
                </ul>
            </li>
            <li>
                <p>06월 17일 (월) 논문 세미나 – 김주봉</p>
                <ul>
                    <li>논문: <a
                            href="https://papers.nips.cc/paper/6042-learning-to-communicate-with-deep-multi-agent-reinforcement-learning.pdf">J.
                        Foerster, “Learning to Communicate with Deep Multi-Agent
                        Reinforcement Learning,” 30th Conference on Neural Information
                        Processing Systems (NIPS 2016), Barcelona, Spain.</a></li>
                    <li>
                        <a href="https://drive.google.com/open?id=1wWUsC5tfWexUOeLSz18rV0ArbnEvoPFc">발표자료</a>
                    </li>
                </ul>
            </li>
            <li>
            <li>06월 10일 (월) 논문 세미나 – 허주성
                <br/>
                <strong>Hyun-Joo
                    Kim, “Design and Implementation of an Efficient Web Services
                    Data Processing Using Hadoop-Based Big Data Processing
                    Technique,” Journal of the Korea Academia-Industrial Cooperation
                    Society, Vol. 16, No. 1 pp. 726-734, 2015</strong>
                <a href="http://www.ndsl.kr/ndsl/commons/util/ndslOriginalView.do?dbt=JAKO&amp;cn=JAKO201507964683971&amp;oCn=JAKO201507964683971&amp;pageCode=PG11&amp;journal=NJOU00294921"
                   target="_blank">
                    <img src="/assets/images/external_link.png"
                         style="width: 1.5em;vertical-align:middle;"/></a>
            </li>
        </ul>
        </li>
        <li>
            <p>05월 27일 (월) 논문 세미나 – 임현교</p>
            <ul>
                <li>논문: <a href="https://arxiv.org/abs/1806.04582">Almuthanna T.
                    Nassar, Yasin Yilmaz, “Reinforcement Learning-based Resource
                    Allocation in Fog RAN for IoT with Heterogeneous Latency
                    Requirements,” arXiv:1806.04582, 2018</a></li>
                <li>
                    <a href="https://www.dropbox.com/s/z7t4e1qf417tr8o/Reinforcement%20Learning-based%20Resource%20Allocation%20in%20Fog%20RAN%20for%20IoT%20with%20Heterogeneous%20Latency%20Requirements.pptx?dl=0">발표자료</a>
                </li>
            </ul>
        </li>
        <li>
            05월 13, 20일 (월) 논문 세미나 – 권도형
            <ul>
                <li>논문: <a
                        href="http://www.aaai.org/Conferences/AAAI/2017/PreliminaryPapers/11-YinH-14478.pdf">H.
                    Yin and S. J. Pan, “Knowledge Transfer for Deep Reinforcement
                    Learning with Hierarchical Experience Replay,” Proceedings of
                    the Thirty-First AAAI Conference on Artificial Intelligence</a>
                </li>
                <li><a href="https://1drv.ms/b/s!AjBcIJ675xCGhbdxZeTDmfyQYB1j2w">발표자료</a>
                </li>
            </ul>
        </li>
        <br/>
        <li>05월 08일 (수) 논문 세미나 – 황규영
            <br/>
            <strong>François Chollet, “Xception: Deep Learning with Depthwise Separable
                Convolutions”, arXiv:1610.02357v3 [cs.CV] 4 Apr 2017.</strong>
            <a href="https://arxiv.org/pdf/1610.02357.pdf"
               target="_blank">
                <img src="/assets/images/external_link.png"
                     style="width: 1.5em;vertical-align:middle;"/>
            </a>
        </li>
        <br/>
        <li>
            <p>04월 29일 (월) 논문 세미나 – 최호빈</p>
            <ul>
                <li>논문: <a href="https://arxiv.org/pdf/1711.00489.pdf">Samuel L.
                    Smith, Pieter-Jan Kindermans, Chris Ying, and Quoc V. Le, “Don’t
                    Decay The Learning Rate, increase The Batch Size,” ICLR
                    2018.</a></li>
                <li><a href="">발표자료</a></li>
            </ul>
        </li>
        <li>
            <p>04월 08일 (월) 논문 세미나 – 임현교</p>
            <ul>
                <li>논문: <a
                        href="https://hal.inria.fr/hal-01933970/file/Deep_Reinforcement_Learning_based_QoS_aware_Routing_in_Software_defined_networking.pdf">Quang
                    Tran Anh Pham, Yassine Hadjadj-Aoul, and Abdelkader Outtagarts,
                    “Deep Reinforcement Learning based QoS-aware Routing in
                    Knowledge-defined networking,” Qshine 2018 – 14th EAI
                    International Conference on Heterogeneous Networking for
                    Quality, Reliability, Security and Robustness, pp. 1-13, Dec,
                    2018.</a></li>
                <li><a href="">발표자료</a></li>
            </ul>
        </li>
        <li>
            <p>04월 01일 (월) 논문 세미나 – 허주성</p>
            <ul>
                <li>논문: <a href="http://ktsde.kips.or.kr/digital-library/15422">AUTOMATIC
                    OBJECT EXTRACTION FROM ELECTRONIC DOCUMENTS USING DEEP NEURAL
                    NETWORK, Heejin Jang, Yeonghun Chae, Sangwon Lee, Jinyong Jo,
                    KIPS Transactions on Software and Data Engineering, Vol. 7, No.
                    11, pp. 411-418, Nov. 2018.</a></li>
                <li><a href="">발표자료</a></li>
            </ul>
        </li>
        <li>
            <p>03월 25일 (월) 논문 세미나 – 최호빈</p>
            <ul>
                <li>논문:<a href="https://arxiv.org/pdf/1801.02852.pdf">Igor Adamski,
                    Robert Adamski, Tomasz Grel, Adam Jędrych, Kamil Kaczmarek,
                    Henryk Michalewski, “Distributed Deep Reinforcement Learning:
                    Learn how to play Atari games in 21 minutes”, arXiv:1801.02852
                    [cs.AI], Jan 2018.</a></li>
                <li><a href="">발표자료</a></li>
            </ul>
        </li>
        <br/>
        <li>03월 18일 (월) 논문 세미나 – 황규영
            <br/>
            <strong> Sartoretti, Y. Wu, W. Paivine, T. K. S. Kumar, S. Koenig, and H.
                Choset, “Distributed Reinforcement Learning for MultiRobot
                Decentralized Collective Construction”, DARS 2018.</strong>
            <a href="http://biorobotics.ri.cmu.edu/papers/paperUploads/DARS2018_DistributedAssembly_final831.pdf"
               target="_blank">
                <img src="/assets/images/external_link.png"
                     style="width: 1.5em;vertical-align:middle;"/>
            </a>
        </li>
        <br/>
        <li>
            <p>03월 11일 (월) 논문 세미나 – 임현교</p>
            <ul>
                <li>논문: <a href="https://arxiv.org/pdf/1707.06347.pdf">J. Schulman,
                    F. Wolski, P. Dhariwal, A. Radford and O. Klimov, “Proximal
                    Policy Optimization Algorithms,” arXiv:1707.06347v2 [cs.LG],
                    Aug. 2017.</a></li>
                <li><a href="">발표자료</a></li>
            </ul>
        </li>
        <li>
            <p>03월 4일 (월) 논문 세미나 – 김주봉</p>
            <ul>
                <li>논문: <a href="https://arxiv.org/pdf/1502.05477.pdf">J. Schulman,
                    S. Levine, P. Moritz, M. Jordan and P. Abbeel, “Trust Region
                    Policy Optimization,” &nbsp;arXiv:1502.05477v5&nbsp;[cs.LG],
                    Apr. 2017.</a></li>
                <li><a href="">발표자료</a></li>
            </ul>
        </li>
        <li>
            <p>02월 25일 (월) 논문 세미나 – 김주봉</p>
            <ul>
                <li>논문: <a
                        href="http://cs231n.stanford.edu/reports/2016/pdfs/122_Report.pdf">M.
                    Egorov, “Multi-Agent Deep Reinforcement Learning,” Stanford
                    University</a></li>
                <li><a href="">발표자료</a></li>
            </ul>
        </li>
        <li>
            <p>02월 15일 (금) 논문 세미나 – 권도형</p>
            <ul>
                <li>논문: <a href="https://arxiv.org/abs/1602.01783">V. Mnih, A.P.
                    Badia, M. Mirza, A. Graves, T.P. Lillicrap, T. Harley, D.
                    Silver, and K. Kavukcuoglu, ” Asynchronous Methods for Deep
                    Reinforcement Learning,” Proceedings of The 33rd International
                    Conference on Machine Learning, vol.48 pp. 1928-1937, 2016.</a>
                </li>
                <li><a href="">발표자료</a></li>
            </ul>
        </li>
        <li>
            <p>02월 07일 (목) 논문 세미나 – 임현교</p>
            <ul>
                <li>논문: <a href="https://ieeexplore.ieee.org/document/8611107">Chin-Feng
                    Lai, Wei-Che Chien, Laurence T. Yang, Weizhong Qiang, “LSTM and
                    Edge Computing for Big Data Feature Recognition of Industrial
                    Electrical Equipment,” IEEE Transactions on Industrial
                    Informatics. PP. 1-1, 2019.</a></li>
                <li><a href="">발표자료</a></li>
            </ul>
        </li>
        <li>
            <p>01월 31일 (목) 논문 세미나 – 김주봉</p>
            <ul>
                <li>논문: <a href="https://arxiv.org/abs/1812.07252">S. James , P.
                    Wohlhart, M. Kalakrishnan, D. Kalashnikov, A. Irpan, J. Ibarz,
                    S. Levine, R. Hadsell, and K. Bousmalis, “Sim-to-Real via
                    Sim-to-Sim: Data-efficient Robotic Grasping via
                    Randomized-to-Canonical Adaptation Networks,” arXiv:1812.07252
                    [cs.RO], Dec. 2018. </a></li>
                <li><a href="">발표자료</a></li>
            </ul>
        </li>
        </ul>
    </div>
</article>
<br/>
<article>
    <button class="accordion">2018</button>
    <div class="panel article-content-1">
        <ul>
            <li>
                12월 20일 (목) 논문 세미나 – 임현교
                <br/>
                <strong>
                    M. Spryn, A. Sharma, D. Parkar, and M. Shrimal, "Distributed Deep
                    Reinforcement Learning on the Cloud for Autonomous Driving,"
                    ACM/IEEE 1st International Workshop on Software Engineering for AI
                    in Autonomous Systems, 2018.
                </strong>
                <a href="#" target="_blank">
                    <img src="/assets/images/external_link.png"
                         style="width: 1.5em;vertical-align:middle;"/>
                </a>
            </li>
        </ul>
    </div>
</article>
<br/>
</section>
<section class="content-wrapper">
    <article>
        <button class="accordion">Papers for Upcoming Seminar</button>
        <div class="panel article-content-1">
            <ul>
                <li><strong>UneVEn: Universal Value Exploration for Multi-Agent Reinforcement Learning <span class="badge badge-info">ICML 2021</span></strong>
                    <a href="http://proceedings.mlr.press/v139/gupta21a.html" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li><strong>Communication in Multi-Agent Reinforcement Learning-Intention Sharing <span class="badge badge-info">ICLR 2021</span></strong>
                    <a href="https://openreview.net/pdf?id=qpsl2dR9twy" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li><strong>Succinct and Robust Multi-Agent Communication With Temporal Message Control <span class="badge badge-info">NIPS 2020</span></strong>
                    <a href="https://papers.nips.cc/paper/2020/file/c82b013313066e0702d58dc70db033ca-Paper.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li><strong>Multi-agent active perception with prediction rewards <span class="badge badge-info">NIPS 2020</span></strong>
                    <a href="https://papers.nips.cc/paper/2020/file/9db6faeef387dc789777227a8bed4d52-Paper.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li><strong>Promoting Coordination through Policy Regularization in Multi-Agent Deep Reinforcement Learning <span class="badge badge-info">NIPS 2020</span></strong>
                    <a href="https://papers.nips.cc/paper/2020/file/b628386c9b92481fab68fbf284bd6a64-Paper.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li><strong>Model-Based Multi-Agent RL in Zero-Sum Markov Games with Near-Optimal Sample Complexity <span class="badge badge-info">NIPS 2020</span></strong>
                    <a href="https://papers.nips.cc/paper/2020/file/0cc6ee01c82fc49c28706e0918f57e2d-Paper.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li><strong>Learning Implicit Credit Assignment for Cooperative Multi-Agent Reinforcement Learning <span class="badge badge-info">NIPS 2020</span></strong>
                    <a href="https://papers.nips.cc/paper/2020/file/8977ecbb8cb82d77fb091c7a7f186163-Paper.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li><strong>Learning Multi-Agent Communication through Structured Attentive Reasoning <span class="badge badge-info">NIPS 2020</span></strong>
                    <a href="https://papers.nips.cc/paper/2020/file/72ab54f9b8c11fae5b923d7f854ef06a-Paper.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li><strong>Shared Experience Actor-Critic for Multi-Agent Reinforcement Learning <span class="badge badge-info">NIPS 2020</span></strong>
                    <a href="https://papers.nips.cc/paper/2020/file/7967cc8e3ab559e68cc944c44b1cf3e8-Paper.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li><strong>Robust Multi-Agent Reinforcement Learning with Model Uncertainty <span class="badge badge-info">NIPS 2020</span></strong>
                    <a href="https://papers.nips.cc/paper/2020/file/774412967f19ea61d448977ad9749078-Paper.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li><strong>Weighted QMIX: Expanding Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning <span class="badge badge-info">NIPS 2020</span></strong>
                    <a href="https://papers.nips.cc/paper/2020/file/73a427badebe0e32caa2e1fc7530b7f3-Paper.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li><strong>Scalable Multi-Agent Reinforcement Learning for Networked Systems with Average Reward <span class="badge badge-info">NIPS 2020</span></strong>
                    <a href="https://papers.nips.cc/paper/2020/file/168efc366c449fab9c2843e9b54e2a18-Paper.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li><strong>Contextual Games: Multi-Agent Learning with Side Information <span class="badge badge-info">NIPS 2020</span></strong>
                    <a href="https://papers.nips.cc/paper/2020/file/f9afa97535cf7c8789a1c50a2cd83787-Paper.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li><strong>Learning Individually Inferred Communication for Multi-Agent Cooperation <span class="badge badge-info">NIPS 2020</span></strong>
                    <a href="https://papers.nips.cc/paper/2020/file/fb2fcd534b0ff3bbed73cc51df620323-Paper.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li><strong>EvolveGraph: Multi-Agent Trajectory Prediction with Dynamic Relational Reasoning <span class="badge badge-info">NIPS 2020</span></strong>
                    <a href="https://papers.nips.cc/paper/2020/file/e4d8163c7a068b65a64c89bd745ec360-Paper.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li><strong>Joint Policy Search for Multi-agent Collaboration with Imperfect Information <span class="badge badge-info">NIPS 2020</span></strong>
                    <a href="https://papers.nips.cc/paper/2020/file/e64f346817ce0c93d7166546ac8ce683-Paper.pdf" target="_blank">
                        <img src="/assets/images/external_link.png" style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li><strong>"ATTENTION, LEARN TO SOLVE ROUTING PROBLEMS!" in conference paper at ICLR 2019</strong>
                    <a href="https://arxiv.org/pdf/1803.08475.pdf"
                       target="_blank">
                        <img src="/assets/images/external_link.png"
                             style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
                <br/>
                <li><strong>"DeepViNE: Virtual Network Embedding with Deep Reinforcement Learning," IEEE INFOCOM 2019.</strong>
                    <a href="https://ieeexplore.ieee.org/document/8845171"
                       target="_blank">
                        <img src="/assets/images/external_link.png"
                             style="width: 1.5em;vertical-align:middle;"/>
                    </a>
                </li>
            </ul>
        </div>
    </article>
</section>

<script type="text/javascript">
    var acc = document.getElementsByClassName("accordion");

    for (var i = 0; i < acc.length; i++) {
        acc[i].addEventListener("click", function () {
            this.classList.toggle("acc_active");
            var panel = this.nextElementSibling;
            if (panel.style.maxHeight) {
                panel.style.maxHeight = null;
            } else {
                panel.style.maxHeight = panel.scrollHeight + "px";
            }
        });
    }

    for (var i = 0; i < acc.length; i++) {
        acc[i].click();
    }

</script>
